{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f00e3570",
   "metadata": {},
   "source": [
    "# Lab 3: Azure AI Foundry Agent Service 기반 Multi-Agent 구축\n",
    "\n",
    "## 개요 (Overview)\n",
    "\n",
    "이 노트북에서는 Azure AI Foundry의 Agent Service를 활용하여 Multi-Agent 시스템을 구축하고 배포합니다.\n",
    "\n",
    "### 아키텍처 (Architecture)\n",
    "\n",
    "```\n",
    "┌────────────────────────────────────────────────────────────┐\n",
    "│                 Multi-Agent System                         │\n",
    "│                                                            │\n",
    "│  ┌─────────────────────────────────────────────┐          │\n",
    "│  │          Main Agent                         │          │\n",
    "│  │  (Task Analysis & Routing)                  │          │\n",
    "│  └────────────┬────────────────┬────────────────┘          │\n",
    "│               │                │                           │\n",
    "│       ┌───────▼──────┐  ┌──────▼──────────┐               │\n",
    "│       │  Tool Agent  │  │  Research       │               │\n",
    "│       │  (MCP)       │  │  Agent (RAG)    │               │\n",
    "│       └──────┬───────┘  └────────┬────────┘               │\n",
    "│              │                   │                         │\n",
    "│       ┌──────▼───────┐    ┌──────▼─────────┐              │\n",
    "│       │  MCP Server  │    │  Azure AI      │              │\n",
    "│       │  (ACA)       │    │  Search (RAG)  │              │\n",
    "│       └──────────────┘    └────────────────┘              │\n",
    "└────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### 주요 구성 요소 (Components)\n",
    "\n",
    "1. **Main Agent**: 사용자 요청을 분석하고 적절한 Agent로 라우팅\n",
    "2. **Tool Agent**: MCP 서버의 도구들을 활용 (실시간 날씨 정보)\n",
    "3. **Research Agent**: Azure AI Search를 통한 지식 베이스 검색\n",
    "4. **MCP Server**: Azure Container Apps에 배포된 도구 서버\n",
    "\n",
    "### Python 모듈 구조 (Python Modules)\n",
    "\n",
    "```\n",
    "src/foundry_agent/\n",
    "├── main_agent.py       - Main Agent 클래스\n",
    "├── tool_agent.py       - Tool Agent 클래스 (MCP)\n",
    "├── research_agent.py   - Research Agent 클래스 (RAG)\n",
    "├── api_server.py       - FastAPI HTTP 서버 (Agent 엔드포인트)\n",
    "├── masking.py          - 마스킹 유틸리티 (PII 보호)\n",
    "└── requirements.txt    - Python 의존성\n",
    "```\n",
    "\n",
    "### 학습 목표 (Learning Objectives)\n",
    "\n",
    "1. ✅ Azure AI Foundry Agent Service 이해 및 활용\n",
    "2. ✅ MCP Server를 Azure Container Apps에 배포\n",
    "3. ✅ Connected Agent를 사용한 MCP 연동\n",
    "4. ✅ Multi-Agent 오케스트레이션 패턴 구현\n",
    "5. ✅ RAG 기반 Agent 구축\n",
    "6. ✅ Agent 간 협업 및 응답 통합"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45fa842",
   "metadata": {},
   "source": [
    "## 1. 환경 설정 및 인증 (Setup & Authentication)\n",
    "\n",
    "### 테넌트 ID 설정 안내\n",
    "\n",
    "**대부분의 경우**: 테넌트 ID를 지정하지 않아도 됩니다. `tenant_id` 변수를 `\"<YOUR_TENANT_ID>\"` 또는 `None`으로 두고 실행하세요.\n",
    "\n",
    "**테넌트 ID가 필요한 경우**:\n",
    "- ✅ 여러 조직(회사)의 Azure 테넌트에 접근 권한이 있는 경우\n",
    "- ✅ 특정 조직의 리소스로만 작업해야 하는 경우\n",
    "- ✅ 로그인 시 \"multiple tenants\" 관련 오류가 발생하는 경우\n",
    "\n",
    "**테넌트 ID 확인 방법**:\n",
    "- Azure Portal → Azure Active Directory → 개요 → 테넌트 ID 복사\n",
    "- 또는 조직 관리자에게 문의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6295d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Prerequisites Check ===\n",
      "✓ Python 3.12.12 (Darwin)\n",
      "✓ Azure CLI\n",
      "✓ Docker\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import sys, subprocess, os, json\n",
    "import platform\n",
    "\n",
    "# 운영체제에 따라 PATH 설정\n",
    "system = platform.system()\n",
    "if system == 'Darwin':  # macOS\n",
    "    extra_paths = '/opt/homebrew/bin:/usr/local/bin'\n",
    "elif system == 'Linux':  # Linux / Codespaces\n",
    "    extra_paths = '/usr/local/bin:/usr/bin:/home/codespace/.local/bin'\n",
    "else:  # Windows\n",
    "    extra_paths = ''\n",
    "\n",
    "if extra_paths:\n",
    "    os.environ['PATH'] = extra_paths + ':' + os.environ.get('PATH', '')\n",
    "\n",
    "def check(cmd, name):\n",
    "    try:\n",
    "        result = subprocess.run(cmd, shell=True, capture_output=True, timeout=3, env=os.environ)\n",
    "        print(f\"{'✓' if result.returncode == 0 else '✗'} {name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ {name}\")\n",
    "\n",
    "print(\"=== Prerequisites Check ===\")\n",
    "print(f\"✓ Python {sys.version.split()[0]} ({system})\")\n",
    "check(\"az --version\", \"Azure CLI\")\n",
    "check(\"docker --version\", \"Docker\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00fd9d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Azure Authentication ===\n",
      "ℹ️  인증 상태를 확인하고 필요시 로그인합니다.\n",
      "\n",
      "✅ Azure CLI 인증 완료 (기존 세션 사용)\n",
      "   구독: Visual Studio Enterprise Subscription\n",
      "   테넌트: 2e8663e8-e15f-4dd9-b617-0cfc4f82adca\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import subprocess, json\n",
    "\n",
    "print(\"=== Azure Authentication ===\")\n",
    "print(\"ℹ️  인증 상태를 확인하고 필요시 로그인합니다.\\n\")\n",
    "\n",
    "# 테넌트 ID를 여기에 입력하세요 (선택사항)\n",
    "# 예: tenant_id = \"16b3c013-d300-468d-ac64-7eda0820b6d3\"\n",
    "tenant_id = \"<YOUR_TENANT_ID>\"  # 또는 None으로 설정하면 기본 테넌트 사용\n",
    "\n",
    "# Azure CLI 인증 상태 확인\n",
    "az_account = subprocess.run(\"az account show\", shell=True, capture_output=True, text=True)\n",
    "\n",
    "if az_account.returncode == 0:\n",
    "    account_info = json.loads(az_account.stdout)\n",
    "    print(f\"✅ Azure CLI 인증 완료 (기존 세션 사용)\")\n",
    "    print(f\"   구독: {account_info.get('name', 'N/A')}\")\n",
    "    print(f\"   테넌트: {account_info.get('tenantId', 'N/A')}\")\n",
    "else:\n",
    "    print(\"⚠️  Azure CLI 인증이 필요합니다. 브라우저가 열립니다...\")\n",
    "    # 테넌트 ID가 설정되어 있으면 해당 테넌트로 로그인\n",
    "    if tenant_id and tenant_id != \"<YOUR_TENANT_ID>\":\n",
    "        az_login = subprocess.run(f\"az login --tenant {tenant_id}\", shell=True)\n",
    "    else:\n",
    "        az_login = subprocess.run(\"az login\", shell=True)\n",
    "    \n",
    "    if az_login.returncode == 0:\n",
    "        print(\"✅ Azure CLI 로그인 완료\")\n",
    "    else:\n",
    "        raise Exception(\"❌ Azure CLI 로그인 실패\")\n",
    "\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "857588b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Configuration Loaded ===\n",
      "Resource Group: rg-aiagent-4sfcl5\n",
      "Location: eastus\n",
      "Search Index: ai-agent-knowledge-base\n",
      "Container Registry: crf5gn2xuprfeyy.azurecr.io\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# 설정 파일 로드\n",
    "config_path = \"config.json\"\n",
    "with open(config_path) as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# 환경 변수 설정\n",
    "RESOURCE_GROUP = config[\"resource_group\"]\n",
    "LOCATION = config[\"location\"]\n",
    "PROJECT_CONNECTION_STRING = config[\"project_connection_string\"]\n",
    "SEARCH_ENDPOINT = config[\"search_endpoint\"]\n",
    "SEARCH_INDEX = config[\"search_index\"]\n",
    "CONTAINER_REGISTRY = config[\"container_registry_endpoint\"]\n",
    "CONTAINER_ENV_ID = config[\"container_apps_environment_id\"]\n",
    "\n",
    "# PROJECT_CONNECTION_STRING을 간단한 형식으로 변환\n",
    "# config.json 형식: https://xxx/api/projects/yyy;subscription_id=zzz;resource_group=www\n",
    "# 필요한 형식: https://xxx/api/projects/yyy (세미콜론 이후 제거)\n",
    "simple_project_conn = PROJECT_CONNECTION_STRING.split(';')[0] if PROJECT_CONNECTION_STRING else \"\"\n",
    "\n",
    "print(\"=== Configuration Loaded ===\")\n",
    "print(f\"Resource Group: {RESOURCE_GROUP}\")\n",
    "print(f\"Location: {LOCATION}\")\n",
    "print(f\"Search Index: {SEARCH_INDEX}\")\n",
    "print(f\"Container Registry: {CONTAINER_REGISTRY}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e705908",
   "metadata": {},
   "source": [
    "## 2. 필수 패키지 설치 (Install Required Packages)\n",
    "\n",
    "Azure AI 관련 필수 패키지를 설치합니다. GitHub Codespace에서 실행하는 경우 대부분의 패키지가 이미 설치되어 있을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f82e709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Installing Required Packages ===\n",
      "\n",
      "Installing azure-ai-projects...\n",
      "✅ azure-ai-projects installed\n",
      "Installing azure-ai-evaluation...\n",
      "✅ azure-ai-evaluation installed\n",
      "Installing azure-ai-inference...\n",
      "✅ azure-ai-inference installed\n",
      "Installing azure-search-documents...\n",
      "✅ azure-search-documents installed\n",
      "Installing azure-identity...\n",
      "✅ azure-identity installed\n",
      "Installing openai...\n",
      "✅ openai installed\n",
      "Installing python-dotenv...\n",
      "✅ python-dotenv installed\n",
      "Installing requests...\n",
      "✅ requests installed\n",
      "\n",
      "==================================================\n",
      "✅ Package installation completed!\n"
     ]
    }
   ],
   "source": [
    "# 필수 패키지 설치\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages = [\n",
    "    \"azure-ai-projects\",\n",
    "    \"azure-ai-evaluation\",\n",
    "    \"azure-ai-inference\",\n",
    "    \"azure-search-documents\",\n",
    "    \"azure-identity\",\n",
    "    \"openai\",\n",
    "    \"python-dotenv\",\n",
    "    \"requests\"\n",
    "]\n",
    "\n",
    "print(\"=== Installing Required Packages ===\\n\")\n",
    "\n",
    "for package in packages:\n",
    "    print(f\"Installing {package}...\")\n",
    "    result = subprocess.run(\n",
    "        [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    if result.returncode == 0:\n",
    "        print(f\"✅ {package} installed\")\n",
    "    else:\n",
    "        print(f\"⚠️  {package} may already be installed or failed to install\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"✅ Package installation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84530d7",
   "metadata": {},
   "source": [
    "## 3. Azure AI Search 키 가져오기 (Get Search Key)\n",
    "\n",
    "RAG Agent가 사용할 Azure AI Search 관리 키를 가져옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35b0ebf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Search key retrieved: X6UoYcyAxt...\n"
     ]
    }
   ],
   "source": [
    "# AI Search 관리 키 가져오기\n",
    "search_name = config[\"search_service_name\"]\n",
    "\n",
    "search_key_cmd = f\"\"\"\n",
    "az search admin-key show \\\n",
    "    --resource-group {RESOURCE_GROUP} \\\n",
    "    --service-name {search_name} \\\n",
    "    --query primaryKey -o tsv\n",
    "\"\"\"\n",
    "\n",
    "result = subprocess.run(search_key_cmd, shell=True, capture_output=True, text=True)\n",
    "SEARCH_KEY = result.stdout.strip()\n",
    "\n",
    "if SEARCH_KEY:\n",
    "    print(f\"✅ Search key retrieved: {SEARCH_KEY[:10]}...\")\n",
    "    os.environ['SEARCH_KEY'] = SEARCH_KEY\n",
    "else:\n",
    "    print(\"❌ Failed to retrieve search key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3063a53c",
   "metadata": {},
   "source": [
    "## 4. Azure AI Search 연결 추가 (Add Azure AI Search Connection)\n",
    "\n",
    "Azure AI Foundry 프로젝트에 Azure AI Search 연결을 추가합니다.\n",
    "\n",
    "**연결 추가 이유:**\n",
    "- `AzureAISearchTool`은 프로젝트 연결을 통해 Azure AI Search에 액세스합니다\n",
    "- 연결이 없으면 Research Agent가 RAG 기능 없이 일반 지식으로만 답변합니다\n",
    "\n",
    "**작업 내용:**\n",
    "- Azure AI Search 서비스 정보를 프로젝트에 연결로 등록\n",
    "- 등록 후 Research Agent가 자동으로 연결을 사용하여 RAG 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16a29169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Checking Azure AI Search Connection ===\n",
      "\n",
      "🔍 Project: https://aoai-f5gn2xuprfeyy.services.ai.azure.com/api/projects/proj-f5gn2xuprfeyy\n",
      "\n",
      "📋 Checking existing connections...\n",
      "\n",
      "✅ Default Azure AI Search connection found!\n",
      "   Connection ID: /subscriptions/8627ae60-01d3-4a2d-9c33-89dea54cd4b4/resourceGroups/rg-aiagent-4sfcl5/providers/Microsoft.CognitiveServices/accounts/aoai-f5gn2xuprfeyy/projects/proj-f5gn2xuprfeyy/connections/srchf5gn2xuprfeyy\n",
      "   Connection Name: srchf5gn2xuprfeyy\n",
      "\n",
      "============================================================\n",
      "✅ Azure AI Search connection is configured!\n",
      "\n",
      "💡 Research Agent will use RAG with this connection.\n",
      "   You can now test the Research Agent.\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Azure AI Search 연결 확인\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import ConnectionType\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "print(\"=== Checking Azure AI Search Connection ===\\n\")\n",
    "\n",
    "# Initialize project client\n",
    "print(f\"🔍 Project: {simple_project_conn}\\n\")\n",
    "\n",
    "project_client_for_connection = AIProjectClient(\n",
    "    endpoint=simple_project_conn,\n",
    "    credential=DefaultAzureCredential()\n",
    ")\n",
    "\n",
    "# Check existing connections\n",
    "print(\"📋 Checking existing connections...\\n\")\n",
    "\n",
    "connection_exists = False\n",
    "\n",
    "try:\n",
    "    # Try to get default Azure AI Search connection\n",
    "    search_connection = project_client_for_connection.connections.get_default(\n",
    "        connection_type=ConnectionType.AZURE_AI_SEARCH\n",
    "    )\n",
    "    print(f\"✅ Default Azure AI Search connection found!\")\n",
    "    print(f\"   Connection ID: {search_connection.id}\")\n",
    "    print(f\"   Connection Name: {search_connection.name}\\n\")\n",
    "    connection_exists = True\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"⚠️  No default connection found: {e}\\n\")\n",
    "    \n",
    "    # Try to list all Azure AI Search connections\n",
    "    try:\n",
    "        print(\"🔍 Searching for any Azure AI Search connections...\")\n",
    "        connections = list(project_client_for_connection.connections.list(\n",
    "            connection_type=ConnectionType.AZURE_AI_SEARCH\n",
    "        ))\n",
    "        \n",
    "        if connections:\n",
    "            print(f\"✅ Found {len(connections)} Azure AI Search connection(s):\\n\")\n",
    "            for conn in connections:\n",
    "                print(f\"   • {conn.name}\")\n",
    "                print(f\"     ID: {conn.id}\\n\")\n",
    "            connection_exists = True\n",
    "        else:\n",
    "            print(\"❌ No Azure AI Search connections found\\n\")\n",
    "            \n",
    "    except Exception as e2:\n",
    "        print(f\"❌ Error listing connections: {e2}\\n\")\n",
    "\n",
    "# Display result\n",
    "print(\"=\"*60)\n",
    "if connection_exists:\n",
    "    print(\"✅ Azure AI Search connection is configured!\")\n",
    "    print(\"\\n💡 Research Agent will use RAG with this connection.\")\n",
    "    print(\"   You can now test the Research Agent.\\n\")\n",
    "else:\n",
    "    print(\"❌ No Azure AI Search connection found\")\n",
    "    print(\"\\n📝 Please add the connection via Azure Portal:\")\n",
    "    print(\"   1. Go to: https://ai.azure.com\")\n",
    "    print(f\"   2. Open project: {simple_project_conn.split('/')[-1]}\")\n",
    "    print(\"   3. Settings → Connections → + New connection\")\n",
    "    print(\"   4. Select: Azure AI Search\")\n",
    "    print(f\"   5. Configure with endpoint: {SEARCH_ENDPOINT}\\n\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85824c72",
   "metadata": {},
   "source": [
    "## 5. MCP Server 배포 (Deploy MCP Server)\n",
    "\n",
    "Model Context Protocol 서버를 Azure Container Apps에 배포합니다.\n",
    "\n",
    "### MCP Server 기능\n",
    "- `get_weather`: 도시별 실시간 날씨 정보 조회\n",
    "  - 데이터 소스: wttr.in API (무료, 신뢰성 높음)\n",
    "  - 지원 언어: 한글/영어 도시명 모두 가능 (예: 'Seoul', '서울')\n",
    "  - 제공 정보: 온도, 체감온도, 날씨상태, 습도, 풍속/풍향, 관측시간\n",
    "\n",
    "### 서버 구성\n",
    "- **프로토콜**: Streamable HTTP (MCP over HTTP with SSE)\n",
    "- **포트**: 8000\n",
    "- **엔드포인트**:\n",
    "  - `POST /mcp` - MCP message handling (Server-Sent Events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8fbcf70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Container Registry Login ===\n",
      "✅ Logged in to crf5gn2xuprfeyy\n",
      "\n",
      "💡 MCP 서버가 업데이트되었습니다. 다음 셀에서 재빌드하세요.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Container Registry에 로그인 (재배포를 위해)\n",
    "registry_name = CONTAINER_REGISTRY.split('.')[0]\n",
    "\n",
    "print(\"=== Container Registry Login ===\")\n",
    "login_cmd = f\"az acr login --name {registry_name}\"\n",
    "result = subprocess.run(login_cmd, shell=True, capture_output=True, text=True)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(f\"✅ Logged in to {registry_name}\")\n",
    "    print(\"\\n💡 MCP 서버가 업데이트되었습니다. 다음 셀에서 재빌드하세요.\")\n",
    "else:\n",
    "    print(f\"❌ Login failed: {result.stderr}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f89b21b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Creating .env file for MCP Server ===\n",
      "\n",
      "✅ Created src/mcp/.env\n",
      "\n",
      "💡 MCP 서버는 현재 환경 변수가 필요하지 않습니다.\n",
      "   하지만 향후 외부 API 연동 시 이 파일에 설정을 추가할 수 있습니다.\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# .env 파일 생성 (MCP Server용 - 향후 확장성을 위해)\n",
    "print(\"=== Creating .env file for MCP Server ===\\n\")\n",
    "\n",
    "# MCP 서버는 현재 환경 변수가 필요하지 않지만, 향후 확장을 위해 빈 파일 생성\n",
    "env_content = \"\"\"# MCP Server Configuration\n",
    "# Add any configuration variables here as needed\n",
    "\n",
    "# Example: API keys, endpoints, etc.\n",
    "# WEATHER_API_KEY=your_api_key_here\n",
    "# EXTERNAL_SERVICE_URL=your_service_url_here\n",
    "\"\"\"\n",
    "\n",
    "env_file_path = \"src/mcp/.env\"\n",
    "\n",
    "try:\n",
    "    with open(env_file_path, 'w') as f:\n",
    "        f.write(env_content)\n",
    "    \n",
    "    print(f\"✅ Created {env_file_path}\")\n",
    "    print(\"\\n💡 MCP 서버는 현재 환경 변수가 필요하지 않습니다.\")\n",
    "    print(\"   하지만 향후 외부 API 연동 시 이 파일에 설정을 추가할 수 있습니다.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Failed to create .env file: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a8af0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Building MCP Server Image ===\n",
      "Image: crf5gn2xuprfeyy.azurecr.io/mcp-server:latest\n",
      "\n",
      "🔨 Building image (linux/amd64)...\n",
      "✅ Build successful (2.1s)\n",
      "\n",
      "📤 Pushing image to registry...\n",
      "✅ Push successful\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# MCP Server 이미지 빌드 및 푸시\n",
    "import time\n",
    "\n",
    "mcp_image = f\"{CONTAINER_REGISTRY}/mcp-server:latest\"\n",
    "\n",
    "print(\"=== Building MCP Server Image ===\")\n",
    "print(f\"Image: {mcp_image}\\n\")\n",
    "\n",
    "# 빌드 (Azure Container Apps용 linux/amd64 플랫폼)\n",
    "build_cmd = f\"docker build --platform linux/amd64 -t {mcp_image} ./src/mcp\"\n",
    "print(\"🔨 Building image (linux/amd64)...\")\n",
    "start_time = time.time()\n",
    "\n",
    "result = subprocess.run(build_cmd, shell=True, capture_output=True, text=True)\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(f\"✅ Build successful ({elapsed:.1f}s)\")\n",
    "else:\n",
    "    print(f\"❌ Build failed: {result.stderr}\")\n",
    "    \n",
    "# 푸시\n",
    "if result.returncode == 0:\n",
    "    print(\"\\n📤 Pushing image to registry...\")\n",
    "    push_cmd = f\"docker push {mcp_image}\"\n",
    "    result = subprocess.run(push_cmd, shell=True, capture_output=True, text=True)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(f\"✅ Push successful\")\n",
    "    else:\n",
    "        print(f\"❌ Push failed: {result.stderr}\")\n",
    "\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c6e4a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Deploying MCP Server to ACA ===\n",
      "App Name: mcp-server\n",
      "\n",
      "🚀 Deploying...\n",
      "✅ Deployment successful\n",
      "\n",
      "🌐 MCP Endpoint: https://mcp-server.gentletree-a093330c.eastus.azurecontainerapps.io\n",
      "✅ Config updated\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# MCP Server를 Container App으로 배포\n",
    "mcp_app_name = \"mcp-server\"\n",
    "\n",
    "print(\"=== Deploying MCP Server to ACA ===\")\n",
    "print(f\"App Name: {mcp_app_name}\\n\")\n",
    "\n",
    "deploy_cmd = f\"\"\"\n",
    "az containerapp create \\\n",
    "    --name {mcp_app_name} \\\n",
    "    --resource-group {RESOURCE_GROUP} \\\n",
    "    --environment {CONTAINER_ENV_ID.split('/')[-1]} \\\n",
    "    --image {mcp_image} \\\n",
    "    --target-port 8000 \\\n",
    "    --ingress external \\\n",
    "    --min-replicas 1 \\\n",
    "    --max-replicas 3 \\\n",
    "    --cpu 0.5 \\\n",
    "    --memory 1.0Gi \\\n",
    "    --registry-server {CONTAINER_REGISTRY}\n",
    "\"\"\"\n",
    "\n",
    "print(\"🚀 Deploying...\")\n",
    "result = subprocess.run(deploy_cmd, shell=True, capture_output=True, text=True)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"✅ Deployment successful\")\n",
    "    \n",
    "    # Get endpoint\n",
    "    show_cmd = f\"\"\"\n",
    "    az containerapp show \\\n",
    "        --name {mcp_app_name} \\\n",
    "        --resource-group {RESOURCE_GROUP} \\\n",
    "        --query properties.configuration.ingress.fqdn -o tsv\n",
    "    \"\"\"\n",
    "    result = subprocess.run(show_cmd, shell=True, capture_output=True, text=True)\n",
    "    MCP_ENDPOINT = f\"https://{result.stdout.strip()}\"\n",
    "    \n",
    "    print(f\"\\n🌐 MCP Endpoint: {MCP_ENDPOINT}\")\n",
    "    \n",
    "    # Update config\n",
    "    config['mcp_endpoint'] = MCP_ENDPOINT\n",
    "    with open(config_path, 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    print(\"✅ Config updated\")\n",
    "else:\n",
    "    print(f\"❌ Deployment failed: {result.stderr}\")\n",
    "    MCP_ENDPOINT = None\n",
    "\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfa3dfe",
   "metadata": {},
   "source": [
    "## 6. Agent Container 빌드 및 배포 (Build & Deploy Agent Container)\n",
    "\n",
    "Agent들을 컨테이너 이미지로 빌드하고 Azure Container Apps에 배포합니다.\n",
    "\n",
    "### 컨테이너에 포함된 Agent 모듈\n",
    "\n",
    "- `main_agent.py` - Main Agent 클래스\n",
    "- `tool_agent.py` - Tool Agent 클래스 \n",
    "- `research_agent.py` - Research Agent 클래스\n",
    "- `api_server.py` - FastAPI 기반 HTTP API 서버\n",
    "- `masking.py` - 마스킹 유틸리티 (PII 보호)\n",
    "\n",
    "### 서버 구성\n",
    "\n",
    "- **프레임워크**: FastAPI\n",
    "- **포트**: 8000\n",
    "- **엔드포인트**:\n",
    "  - `/health` - Health check\n",
    "  - `/` - Root (Agent 상태 정보)\n",
    "  - `/chat` - Agent 대화 엔드포인트 (POST)\n",
    "\n",
    "### MCP 서버 제공 기능\n",
    "\n",
    "- **실시간 날씨 정보**:\n",
    "  - `get_weather(location)` - 전 세계 도시의 정확한 실시간 날씨 정보\n",
    "  - 데이터 소스: wttr.in API (무료, 신뢰성 높음)\n",
    "  - 지원 언어: 한글/영어 도시명 모두 가능 (예: 'Seoul', '서울')\n",
    "  - 제공 정보: 온도, 체감온도, 날씨상태, 습도, 풍속/풍향, 관측시간\n",
    "\n",
    "### 환경 변수 설정\n",
    "\n",
    "`.env` 파일에 다음 변수들이 자동으로 설정됩니다:\n",
    "\n",
    "- `PROJECT_CONNECTION_STRING` - Azure AI Foundry 프로젝트 연결 문자열\n",
    "- `SEARCH_ENDPOINT`, `SEARCH_KEY`, `SEARCH_INDEX` - Azure AI Search 설정\n",
    "- `MCP_ENDPOINT` - MCP Server 엔드포인트\n",
    "- `APPLICATIONINSIGHTS_CONNECTION_STRING` - Application Insights 연결 (Application Analytics용)\n",
    "- `OTEL_SERVICE_NAME`, `OTEL_TRACES_EXPORTER`, `OTEL_METRICS_EXPORTER`, `OTEL_LOGS_EXPORTER`, `OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED` - OpenTelemetry 설정 (Tracing용)\n",
    "- `AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED` - Prompt/Completion 기록 활성화 (Tracing UI용)\n",
    "- `AGENT_MASKING_MODE` - 마스킹 강도 설정 (off/standard/strict)\n",
    "\n",
    "### 배포 아키텍처\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────┐\n",
    "│      Azure Container Apps Environment               │\n",
    "│                                                     │\n",
    "│  ┌──────────────────┐  ┌──────────────────────┐   │\n",
    "│  │  MCP Server      │  │  Agent Service       │   │\n",
    "│  │  (Weather API)   │  │  (Multi-Agent)       │   │\n",
    "│  │  :8000           │  │  :8000               │   │\n",
    "│  │                  │  │                      │   │\n",
    "│  │  • get_weather() │  │  • Main Agent        │   │\n",
    "│  │                  │  │  • Tool Agent ────┐  │   │\n",
    "│  └──────────────────┘  │  • Research Agent │  │   │\n",
    "│          ▲             │                   │  │   │\n",
    "│          │             │                   │  │   │\n",
    "│          └─────────────┼───────────────────┘  │   │\n",
    "│                        │                      │   │\n",
    "│                        │  + Azure AI Search   │   │\n",
    "│                        │  + Azure OpenAI      │   │\n",
    "│                        └──────────────────────┘   │\n",
    "└─────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ff91932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Creating .env file for Agent Container ===\n",
      "\n",
      "📊 Getting Application Insights connection string...\n",
      "✅ Application Insights connection string retrieved\n",
      "\n",
      "📦 Model Configuration:\n",
      "   Deployment Name: gpt-4o\n",
      "   Model Version: 2024-11-20\n",
      "   Capacity (TPM): 50\n",
      "   (from config.json - set in Lab 1 infrastructure deployment)\n",
      "\n",
      "✅ Created src/foundry_agent/.env\n",
      "\n",
      "📋 Environment variables:\n",
      "   • PROJECT_CONNECTION_STRING\n",
      "   • AZURE_AI_MODEL_DEPLOYMENT_NAME\n",
      "   • AZURE_AI_MODEL_VERSION\n",
      "   • SEARCH_ENDPOINT\n",
      "   • SEARCH_KEY\n",
      "   • SEARCH_INDEX\n",
      "   • MCP_ENDPOINT\n",
      "   • APPLICATIONINSIGHTS_CONNECTION_STRING\n",
      "   • OTEL_SERVICE_NAME\n",
      "   • OTEL_TRACES_EXPORTER\n",
      "   • OTEL_METRICS_EXPORTER\n",
      "   • OTEL_LOGS_EXPORTER\n",
      "   • OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED\n",
      "   • AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED\n",
      "   • AGENT_MASKING_MODE\n",
      "\n",
      "💡 이 파일은 Docker 이미지에 포함됩니다.\n",
      "   배포 시 별도의 환경 변수 설정이 필요하지 않습니다.\n",
      "\n",
      "✅ Application Insights 설정 완료!\n",
      "   → Application Analytics에서 메트릭을 확인할 수 있습니다.\n",
      "   → OpenTelemetry Tracing 설정 완료!\n",
      "   → GenAI content recording 활성화 (Input/Output 기록 시도)\n",
      "\n",
      "🔐 Masking Mode: standard (AGENT_MASKING_MODE 변수로 조정 가능)\n",
      "🤖 Model: gpt-4o (version 2024-11-20, capacity 50K TPM)\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# .env 파일 생성 (Agent Container에 포함될 환경 변수)\n",
    "print(\"=== Creating .env file for Agent Container ===\\n\")\n",
    "\n",
    "# 1. Application Insights Connection String 가져오기\n",
    "print(\"📊 Getting Application Insights connection string...\")\n",
    "appinsights_cmd = f\"\"\"\n",
    "az monitor app-insights component show \\\n",
    "    --resource-group {RESOURCE_GROUP} \\\n",
    "    --query \"[0].connectionString\" -o tsv\n",
    "\"\"\"\n",
    "\n",
    "result = subprocess.run(appinsights_cmd, shell=True, capture_output=True, text=True)\n",
    "\n",
    "if result.returncode == 0 and result.stdout.strip():\n",
    "    APP_INSIGHTS_CONN_STR = result.stdout.strip()\n",
    "    print(f\"✅ Application Insights connection string retrieved\\n\")\n",
    "else:\n",
    "    print(f\"⚠️  Could not get Application Insights connection string\")\n",
    "    print(f\"   Error: {result.stderr}\")\n",
    "    print(f\"   Proceeding without Application Insights (Analytics will not work)\\n\")\n",
    "    APP_INSIGHTS_CONN_STR = \"\"\n",
    "\n",
    "# 2. 모델 설정 가져오기 (config.json에서)\n",
    "model_deployment_name = config.get(\"model_deployment_name\", \"gpt-4o\")\n",
    "model_version = config.get(\"model_version\", \"2024-11-20\")\n",
    "model_capacity = config.get(\"model_capacity\", 50)\n",
    "print(f\"📦 Model Configuration:\")\n",
    "print(f\"   Deployment Name: {model_deployment_name}\")\n",
    "print(f\"   Model Version: {model_version}\")\n",
    "print(f\"   Capacity (TPM): {model_capacity}\")\n",
    "print(f\"   (from config.json - set in Lab 1 infrastructure deployment)\\n\")\n",
    "\n",
    "# 3. .env 파일 생성\n",
    "\"\"\"\n",
    "NOTE: AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED=true 를 추가하여\n",
    "Tracing UI에서 Input/Output(프롬프트, completion) 기록을 활성화합니다.\n",
    "AGENT_MASKING_MODE 는 프롬프트/응답 마스킹 강도를 제어합니다 (off|standard|strict).\n",
    "\"\"\"\n",
    "env_content = f\"\"\"# Azure AI Foundry Configuration\n",
    "PROJECT_CONNECTION_STRING={simple_project_conn}\n",
    "\n",
    "# Model Configuration\n",
    "# The model deployment name and version from Azure OpenAI\n",
    "# These values are automatically set from Lab 1 infrastructure deployment (infra/main.bicep)\n",
    "AZURE_AI_MODEL_DEPLOYMENT_NAME={model_deployment_name}\n",
    "AZURE_AI_MODEL_VERSION={model_version}\n",
    "\n",
    "# Azure AI Search Configuration\n",
    "SEARCH_ENDPOINT={SEARCH_ENDPOINT}\n",
    "SEARCH_KEY={SEARCH_KEY}\n",
    "SEARCH_INDEX={SEARCH_INDEX}\n",
    "\n",
    "# MCP Server Configuration\n",
    "MCP_ENDPOINT={MCP_ENDPOINT if MCP_ENDPOINT else ''}\n",
    "\n",
    "# Application Insights Configuration (for Application Analytics)\n",
    "APPLICATIONINSIGHTS_CONNECTION_STRING={APP_INSIGHTS_CONN_STR}\n",
    "\n",
    "# OpenTelemetry Configuration (for Tracing)\n",
    "OTEL_SERVICE_NAME=azure-ai-agent\n",
    "OTEL_TRACES_EXPORTER=azure_monitor\n",
    "OTEL_METRICS_EXPORTER=azure_monitor\n",
    "OTEL_LOGS_EXPORTER=azure_monitor\n",
    "OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true\n",
    "AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED=true  # Enable GenAI content capture for tracing UI\n",
    "\n",
    "# Masking / PII Handling\n",
    "AGENT_MASKING_MODE=standard  # off|standard|strict (span prompt/completion masking mode)\n",
    "\"\"\"\n",
    "\n",
    "env_file_path = \"src/foundry_agent/.env\"\n",
    "\n",
    "try:\n",
    "    with open(env_file_path, 'w') as f:\n",
    "        f.write(env_content)\n",
    "    \n",
    "    print(f\"✅ Created {env_file_path}\")\n",
    "    print(\"\\n📋 Environment variables:\")\n",
    "    for line in env_content.strip().split('\\n'):\n",
    "        if line and not line.startswith('#'):\n",
    "            key = line.split('=')[0]\n",
    "            print(f\"   • {key}\")\n",
    "    \n",
    "    print(\"\\n💡 이 파일은 Docker 이미지에 포함됩니다.\")\n",
    "    print(\"   배포 시 별도의 환경 변수 설정이 필요하지 않습니다.\")\n",
    "    \n",
    "    if APP_INSIGHTS_CONN_STR:\n",
    "        print(\"\\n✅ Application Insights 설정 완료!\")\n",
    "        print(\"   → Application Analytics에서 메트릭을 확인할 수 있습니다.\")\n",
    "        print(\"   → OpenTelemetry Tracing 설정 완료!\")\n",
    "        print(\"   → GenAI content recording 활성화 (Input/Output 기록 시도)\")\n",
    "    else:\n",
    "        print(\"\\n⚠️  Application Insights 미설정\")\n",
    "        print(\"   → Application Analytics는 작동하지 않지만 Agent는 정상 작동합니다.\")\n",
    "    \n",
    "    print(\"\\n🔐 Masking Mode: standard (AGENT_MASKING_MODE 변수로 조정 가능)\")\n",
    "    print(f\"🤖 Model: {model_deployment_name} (version {model_version}, capacity {model_capacity}K TPM)\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Failed to create .env file: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a391560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Building Agent Service Image ===\n",
      "Image: crf5gn2xuprfeyy.azurecr.io/agent-service:latest\n",
      "\n",
      "🔨 Building image (linux/amd64)...\n",
      "✅ Build successful (1.5s)\n",
      "   Image contains: main_agent.py, tool_agent.py, research_agent.py\n",
      "\n",
      "📤 Pushing image to registry...\n",
      "✅ Push successful\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Agent Container 이미지 빌드 및 푸시\n",
    "import time\n",
    "\n",
    "agent_image = f\"{CONTAINER_REGISTRY}/agent-service:latest\"\n",
    "\n",
    "print(\"=== Building Agent Service Image ===\")\n",
    "print(f\"Image: {agent_image}\\n\")\n",
    "\n",
    "# 빌드 (Azure Container Apps용 linux/amd64 플랫폼)\n",
    "build_cmd = f\"docker build --platform linux/amd64 -t {agent_image} ./src/foundry_agent\"\n",
    "print(\"🔨 Building image (linux/amd64)...\")\n",
    "start_time = time.time()\n",
    "\n",
    "result = subprocess.run(build_cmd, shell=True, capture_output=True, text=True)\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(f\"✅ Build successful ({elapsed:.1f}s)\")\n",
    "    print(f\"   Image contains: main_agent.py, tool_agent.py, research_agent.py\")\n",
    "else:\n",
    "    print(f\"❌ Build failed: {result.stderr}\")\n",
    "    \n",
    "# 푸시\n",
    "if result.returncode == 0:\n",
    "    print(\"\\n📤 Pushing image to registry...\")\n",
    "    push_cmd = f\"docker push {agent_image}\"\n",
    "    result = subprocess.run(push_cmd, shell=True, capture_output=True, text=True)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(f\"✅ Push successful\")\n",
    "    else:\n",
    "        print(f\"❌ Push failed: {result.stderr}\")\n",
    "\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba682df",
   "metadata": {},
   "source": [
    "## 7. Azure 리소스 확인 (Verify Azure Resources)\n",
    "\n",
    "Agent Service 배포 전에 필요한 Azure 리소스를 확인합니다.\n",
    "\n",
    "**확인 항목:**\n",
    "- ✅ Azure AI Project 리소스 ID\n",
    "- ✅ AI Services (Cognitive Services) 리소스 ID\n",
    "\n",
    "이 정보는 다음 배포 단계에서 Managed Identity에 권한을 자동으로 부여할 때 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb49c923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Verifying Azure Resources ===\n",
      "\n",
      "📋 Project Information:\n",
      "   Resource Group: rg-aiagent-4sfcl5\n",
      "   Project Name: proj-f5gn2xuprfeyy\n",
      "\n",
      "🔍 Finding AI Project resource...\n",
      "   ✅ AI Project Resource ID:\n",
      "   /subscriptions/8627ae60-01d3-4a2d-9c33-89dea54cd4b4/resourceGroups/rg-aiagent-4sfcl5/providers/Microsoft.CognitiveServices/accounts/aoai-f5gn2xuprfeyy/projects/proj-f5gn2xuprfeyy\n",
      "\n",
      "🔍 Finding AI Services (Cognitive Services) resource...\n",
      "   ✅ AI Services Resource ID:\n",
      "   /subscriptions/8627ae60-01d3-4a2d-9c33-89dea54cd4b4/resourceGroups/rg-aiagent-4sfcl5/providers/Microsoft.CognitiveServices/accounts/aoai-f5gn2xuprfeyy\n",
      "\n",
      "✅ All required resources verified!\n",
      "\n",
      "💡 다음 단계에서 이 리소스들에 권한을 부여합니다.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Azure AI Project 및 AI Services 리소스 ID 확인\n",
    "print(\"=== Verifying Azure Resources ===\\n\")\n",
    "\n",
    "# 1. config.json에서 정보 가져오기 (이미 로드됨)\n",
    "# config.json의 PROJECT_CONNECTION_STRING은 이미 간단한 형식:\n",
    "# https://xxx.services.ai.azure.com/api/projects/yyy\n",
    "\n",
    "# URL에서 project_name 추출\n",
    "if '/api/projects/' in simple_project_conn:\n",
    "    project_name = simple_project_conn.split('/api/projects/')[-1].strip()\n",
    "else:\n",
    "    project_name = None\n",
    "\n",
    "print(f\"📋 Project Information:\")\n",
    "print(f\"   Resource Group: {RESOURCE_GROUP}\")\n",
    "print(f\"   Project Name: {project_name if project_name else 'Not found in connection string'}\\n\")\n",
    "\n",
    "# 2. AI Project 리소스 ID 가져오기\n",
    "# Azure AI Foundry Project는 Microsoft.CognitiveServices/accounts/projects 타입\n",
    "print(\"🔍 Finding AI Project resource...\")\n",
    "if project_name:\n",
    "    # project_name을 포함하는 리소스 검색\n",
    "    ai_project_cmd = f\"\"\"\n",
    "    az resource list \\\n",
    "        --resource-group {RESOURCE_GROUP} \\\n",
    "        --query \"[?contains(name, '{project_name}') && type=='Microsoft.CognitiveServices/accounts/projects'].id\" -o tsv\n",
    "    \"\"\"\n",
    "else:\n",
    "    # 타입으로만 검색 (첫 번째 결과)\n",
    "    ai_project_cmd = f\"\"\"\n",
    "    az resource list \\\n",
    "        --resource-group {RESOURCE_GROUP} \\\n",
    "        --query \"[?type=='Microsoft.CognitiveServices/accounts/projects'].id | [0]\" -o tsv\n",
    "    \"\"\"\n",
    "\n",
    "result = subprocess.run(ai_project_cmd, shell=True, capture_output=True, text=True)\n",
    "if result.returncode == 0 and result.stdout.strip():\n",
    "    ai_project_resource_id = result.stdout.strip()\n",
    "    print(f\"   ✅ AI Project Resource ID:\")\n",
    "    print(f\"   {ai_project_resource_id}\\n\")\n",
    "else:\n",
    "    print(f\"   ❌ Could not find AI Project\")\n",
    "    print(f\"   Error: {result.stderr}\\n\")\n",
    "    raise Exception(\"AI Project not found\")\n",
    "\n",
    "# 3. AI Services 리소스 ID 가져오기 (Cognitive Services account)\n",
    "print(\"🔍 Finding AI Services (Cognitive Services) resource...\")\n",
    "ai_services_cmd = f\"\"\"\n",
    "az resource list \\\n",
    "    --resource-group {RESOURCE_GROUP} \\\n",
    "    --resource-type Microsoft.CognitiveServices/accounts \\\n",
    "    --query \"[0].id\" -o tsv\n",
    "\"\"\"\n",
    "\n",
    "result = subprocess.run(ai_services_cmd, shell=True, capture_output=True, text=True)\n",
    "if result.returncode == 0 and result.stdout.strip():\n",
    "    ai_services_resource_id = result.stdout.strip()\n",
    "    print(f\"   ✅ AI Services Resource ID:\")\n",
    "    print(f\"   {ai_services_resource_id}\\n\")\n",
    "else:\n",
    "    print(f\"   ❌ Could not find AI Services\")\n",
    "    print(f\"   Error: {result.stderr}\\n\")\n",
    "    raise Exception(\"AI Services not found\")\n",
    "\n",
    "print(\"✅ All required resources verified!\")\n",
    "print(\"\\n💡 다음 단계에서 이 리소스들에 권한을 부여합니다.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4319f207",
   "metadata": {},
   "source": [
    "## 8. Agent Service 배포 및 권한 설정 (Deploy Agent Service with Permissions)\n",
    "\n",
    "Agent Service를 배포하고 **배포 직후 자동으로** Managed Identity를 구성합니다.\n",
    "\n",
    "### 자동 수행 작업\n",
    "\n",
    "1. ✅ Container App 배포\n",
    "2. ✅ System-assigned Managed Identity 활성화\n",
    "3. ✅ Azure AI User 역할 할당 (AI Project scope) ← agents/write 권한\n",
    "4. ✅ 권한 전파 대기 및 Container 재시작\n",
    "\n",
    "> 💡 **중요**: 배포와 권한 설정을 한 번에 처리하므로 완료까지 약 3-4분 소요됩니다.\n",
    "> \n",
    "> ⚠️ **참고**: Managed Identity는 Container App이 생성된 후에만 활성화할 수 있으므로, 배포 직후 즉시 권한을 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36d8b217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Deploying Agent Service to ACA ===\n",
      "App Name: agent-service\n",
      "\n",
      "💡 환경 변수는 이미 Docker 이미지에 포함되어 있습니다.\n",
      "   별도의 환경 변수 설정이 필요하지 않습니다.\n",
      "\n",
      "🚀 Deploying Agent Service with Managed Identity...\n",
      "   (Starting with 0 replicas to configure permissions first)\n",
      "✅ Deployment successful\n",
      "\n",
      "🌐 Agent Endpoint: https://agent-service.gentletree-a093330c.eastus.azurecontainerapps.io\n",
      "✅ Config updated\n",
      "\n",
      "============================================================\n",
      "🔐 Configuring Permissions\n",
      "\n",
      "1️⃣ Getting Managed Identity Principal ID...\n",
      "   ✅ Principal ID: 187d539c-ca2c-4f87-852a-0308a8184eaa\n",
      "\n",
      "4️⃣ Assigning 'Azure AI User' role to AI Project...\n",
      "   Scope: /subscriptions/8627ae60-01d3-4a2d-9c33-89dea54cd4b4/resourceGroups/rg-aiagent-4sfcl5/providers/Microsoft.CognitiveServices/accounts/aoai-f5gn2xuprfeyy/projects/proj-f5gn2xuprfeyy\n",
      "   ✅ Azure AI User role assigned (AI Project scope)\n",
      "\n",
      "5️⃣ Verifying role assignments...\n",
      "\n",
      "   📋 Current Role Assignments (0 total):\n",
      "\n",
      "\n",
      "   🔍 Required Roles Verification:\n",
      "      ❌ Azure AI User (AI Project)\n",
      "\n",
      "   ❌ Some required roles are missing!\n",
      "      이 문제가 발생하면 Azure Portal에서 수동으로 권한을 확인하세요.\n",
      "\n",
      "============================================================\n",
      "6️⃣ Permissions assigned - waiting for propagation...\n",
      "\n",
      "⚠️  Azure RBAC 권한 전파는 최대 5-10분 소요될 수 있습니다.\n",
      "   Container는 replicas=0 상태로 유지됩니다.\n",
      "\n",
      "📋 다음 단계:\n",
      "   1. 위의 'Required Roles Verification'이 모두 ✅인지 확인\n",
      "   2. 2-3분 정도 기다리세요\n",
      "   3. 아래 셀(섹션 5.2.1)을 실행하여 Container를 시작하세요\n",
      "   4. 만약 여전히 권한 오류가 발생하면:\n",
      "      → 추가로 2-3분 더 기다린 후 섹션 5.2.1을 다시 실행하세요\n",
      "\n",
      "💡 Principal ID (권한 확인용): 187d539c-ca2c-4f87-852a-0308a8184eaa\n",
      "\n",
      "============================================================\n",
      "✅ Permissions configured successfully!\n",
      "\n",
      "🌐 Endpoint: https://agent-service.gentletree-a093330c.eastus.azurecontainerapps.io\n",
      "\n",
      "📋 Assigned Roles:\n",
      "   • Azure AI User (AI Project scope) ← agents/write 권한\n",
      "\n",
      "⏳ 권한 전파를 기다린 후 다음 셀(5.2.1)을 실행하세요!\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Agent Service를 Container App으로 배포 + Managed Identity 권한 설정\n",
    "agent_app_name = \"agent-service\"\n",
    "\n",
    "print(\"=== Deploying Agent Service to ACA ===\")\n",
    "print(f\"App Name: {agent_app_name}\\n\")\n",
    "\n",
    "print(\"💡 환경 변수는 이미 Docker 이미지에 포함되어 있습니다.\")\n",
    "print(\"   별도의 환경 변수 설정이 필요하지 않습니다.\\n\")\n",
    "\n",
    "# 1. Container App 배포 (Managed Identity 포함, 권한 부여 전까지 replicas 0)\n",
    "deploy_cmd = f\"\"\"\n",
    "az containerapp create \\\n",
    "    --name {agent_app_name} \\\n",
    "    --resource-group {RESOURCE_GROUP} \\\n",
    "    --environment {CONTAINER_ENV_ID.split('/')[-1]} \\\n",
    "    --image {agent_image} \\\n",
    "    --target-port 8000 \\\n",
    "    --ingress external \\\n",
    "    --min-replicas 0 \\\n",
    "    --max-replicas 3 \\\n",
    "    --cpu 1.0 \\\n",
    "    --memory 2.0Gi \\\n",
    "    --registry-server {CONTAINER_REGISTRY} \\\n",
    "    --system-assigned \\\n",
    "\"\"\"\n",
    "\n",
    "print(\"🚀 Deploying Agent Service with Managed Identity...\")\n",
    "print(\"   (Starting with 0 replicas to configure permissions first)\")\n",
    "result = subprocess.run(deploy_cmd, shell=True, capture_output=True, text=True, timeout=180)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"✅ Deployment successful\\n\")\n",
    "    \n",
    "    # Get endpoint\n",
    "    show_cmd = f\"\"\"\n",
    "    az containerapp show \\\n",
    "        --name {agent_app_name} \\\n",
    "        --resource-group {RESOURCE_GROUP} \\\n",
    "        --query properties.configuration.ingress.fqdn -o tsv\n",
    "    \"\"\"\n",
    "    result = subprocess.run(show_cmd, shell=True, capture_output=True, text=True)\n",
    "    AGENT_ENDPOINT = f\"https://{result.stdout.strip()}\"\n",
    "    \n",
    "    print(f\"🌐 Agent Endpoint: {AGENT_ENDPOINT}\")\n",
    "    \n",
    "    # Update config\n",
    "    config['agent_endpoint'] = AGENT_ENDPOINT\n",
    "    with open(config_path, 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    print(\"✅ Config updated\\n\")\n",
    "    \n",
    "    # 2. Managed Identity Principal ID 가져오기\n",
    "    print(\"=\"*60)\n",
    "    print(\"🔐 Configuring Permissions\\n\")\n",
    "    \n",
    "    print(\"1️⃣ Getting Managed Identity Principal ID...\")\n",
    "    identity_cmd = f\"\"\"\n",
    "    az containerapp show \\\n",
    "        --name {agent_app_name} \\\n",
    "        --resource-group {RESOURCE_GROUP} \\\n",
    "        --query identity.principalId -o tsv\n",
    "    \"\"\"\n",
    "    \n",
    "    result = subprocess.run(identity_cmd, shell=True, capture_output=True, text=True)\n",
    "    if result.returncode == 0 and result.stdout.strip():\n",
    "        principal_id = result.stdout.strip()\n",
    "        print(f\"   ✅ Principal ID: {principal_id}\\n\")\n",
    "    else:\n",
    "        print(f\"   ❌ Failed to get Principal ID: {result.stderr}\\n\")\n",
    "        raise Exception(\"Failed to get Managed Identity Principal ID\")\n",
    "    \n",
    "    # 3. Azure AI User 역할 할당 (AI Project scope - agents/write 권한용)\n",
    "    print(\"4️⃣ Assigning 'Azure AI User' role to AI Project...\")\n",
    "    print(f\"   Scope: {ai_project_resource_id}\")\n",
    "    role_assignment_cmd = f\"\"\"\n",
    "    az role assignment create \\\n",
    "        --assignee {principal_id} \\\n",
    "        --role \"Azure AI User\" \\\n",
    "        --scope {ai_project_resource_id}\n",
    "    \"\"\"\n",
    "    \n",
    "    result = subprocess.run(role_assignment_cmd, shell=True, capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(\"   ✅ Azure AI User role assigned (AI Project scope)\\n\")\n",
    "    elif \"already exists\" in result.stderr.lower():\n",
    "        print(\"   ✅ Azure AI User role already exists (AI Project scope)\\n\")\n",
    "    else:\n",
    "        print(f\"   ❌ Role assignment FAILED!\")\n",
    "        print(f\"   Error: {result.stderr}\")\n",
    "        print(f\"   Return code: {result.returncode}\\n\")\n",
    "    \n",
    "    # 4. 권한 할당 검증\n",
    "    print(\"5️⃣ Verifying role assignments...\\n\")\n",
    "    import time\n",
    "    time.sleep(5)  # 잠깐 대기 (역할 할당 API 완료 확인)\n",
    "    \n",
    "    role_check_cmd = f\"\"\"\n",
    "    az role assignment list \\\n",
    "        --assignee {principal_id} \\\n",
    "        --query \"[].{{role:roleDefinitionName, scope:scope}}\" -o json\n",
    "    \"\"\"\n",
    "    \n",
    "    result = subprocess.run(role_check_cmd, shell=True, capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        import json as json_lib\n",
    "        current_roles = json_lib.loads(result.stdout)\n",
    "        \n",
    "        print(f\"   📋 Current Role Assignments ({len(current_roles)} total):\\n\")\n",
    "        \n",
    "        # 필요한 역할 체크\n",
    "        required_roles = {\n",
    "            \"Azure AI User (AI Project)\": False\n",
    "        }\n",
    "        \n",
    "        for role in current_roles:\n",
    "            scope_parts = role['scope'].split('/')\n",
    "            resource_name = scope_parts[-1] if scope_parts else 'Unknown'\n",
    "            role_name = role['role']\n",
    "            \n",
    "            print(f\"      • {role_name} → {resource_name}\")\n",
    "            \n",
    "            if role_name == \"Azure AI User\":\n",
    "                if \"projects\" in role['scope'] or ai_project_resource_id in role['scope']:\n",
    "                    required_roles[\"Azure AI User (AI Project)\"] = True\n",
    "        \n",
    "        print(f\"\\n   🔍 Required Roles Verification:\")\n",
    "        all_roles_ok = True\n",
    "        for role_name, assigned in required_roles.items():\n",
    "            status = \"✅\" if assigned else \"❌\"\n",
    "            print(f\"      {status} {role_name}\")\n",
    "            if not assigned:\n",
    "                all_roles_ok = False\n",
    "        \n",
    "        if all_roles_ok:\n",
    "            print(f\"\\n   ✅ All required roles are assigned!\\n\")\n",
    "        else:\n",
    "            print(f\"\\n   ❌ Some required roles are missing!\")\n",
    "            print(f\"      이 문제가 발생하면 Azure Portal에서 수동으로 권한을 확인하세요.\\n\")\n",
    "    else:\n",
    "        print(f\"   ⚠️  Could not verify roles: {result.stderr}\\n\")\n",
    "    \n",
    "    # 5. 권한 전파 대기 안내\n",
    "    print(\"=\"*60)\n",
    "    print(\"6️⃣ Permissions assigned - waiting for propagation...\\n\")\n",
    "    print(\"⚠️  Azure RBAC 권한 전파는 최대 5-10분 소요될 수 있습니다.\")\n",
    "    print(\"   Container는 replicas=0 상태로 유지됩니다.\\n\")\n",
    "    \n",
    "    print(\"📋 다음 단계:\")\n",
    "    print(\"   1. 위의 'Required Roles Verification'이 모두 ✅인지 확인\")\n",
    "    print(\"   2. 2-3분 정도 기다리세요\")\n",
    "    print(\"   3. 아래 셀(섹션 5.2.1)을 실행하여 Container를 시작하세요\")\n",
    "    print(\"   4. 만약 여전히 권한 오류가 발생하면:\")\n",
    "    print(\"      → 추가로 2-3분 더 기다린 후 섹션 5.2.1을 다시 실행하세요\\n\")\n",
    "    \n",
    "    print(f\"💡 Principal ID (권한 확인용): {principal_id}\\n\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"✅ Permissions configured successfully!\")\n",
    "    print(f\"\\n🌐 Endpoint: {AGENT_ENDPOINT}\")\n",
    "    print(f\"\\n📋 Assigned Roles:\")\n",
    "    print(f\"   • Azure AI User (AI Project scope) ← agents/write 권한\")\n",
    "    print(f\"\\n⏳ 권한 전파를 기다린 후 다음 셀(5.2.1)을 실행하세요!\")\n",
    "else:\n",
    "    print(f\"❌ Deployment failed: {result.stderr}\")\n",
    "    AGENT_ENDPOINT = None\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455f3ae4",
   "metadata": {},
   "source": [
    "## 9. Agent Service 시작 (Start Agent Service)\n",
    "\n",
    "권한 전파가 완료된 후 이 셀을 실행하여 Container를 시작합니다.\n",
    "\n",
    "**실행 시점:**\n",
    "- ⏰ 섹션 5.2 완료 후 **2-3분 대기**\n",
    "- ⚠️ 권한 오류 발생 시: 추가로 2-3분 더 기다린 후 재실행\n",
    "\n",
    "**수행 작업:**\n",
    "- ✅ Container App을 replicas=1로 확장\n",
    "- ✅ Container 시작 및 상태 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82fa93d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Scaling to 1 replica...\n",
      "✅ Agent Service started successfully!\n",
      "\n",
      "🌐 Endpoint: https://agent-service.gentletree-a093330c.eastus.azurecontainerapps.io\n",
      "\n",
      "💡 Container가 시작되는 데 약 30초 정도 소요됩니다.\n",
      "   로그 확인: az containerapp logs show --name agent-service --resource-group rg-aiagent-4sfcl5 --tail 50\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# replicas를 1로 확장\n",
    "scale_cmd = f\"\"\"\n",
    "az containerapp update \\\n",
    "    --name agent-service \\\n",
    "    --resource-group {RESOURCE_GROUP} \\\n",
    "    --min-replicas 1 \\\n",
    "    --max-replicas 1\n",
    "\"\"\"\n",
    "\n",
    "print(\"🚀 Scaling to 1 replica...\")\n",
    "result = subprocess.run(scale_cmd, shell=True, capture_output=True, text=True, timeout=120)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"✅ Agent Service started successfully!\")\n",
    "    print(f\"\\n🌐 Endpoint: {AGENT_ENDPOINT}\")\n",
    "    print(\"\\n💡 Container가 시작되는 데 약 30초 정도 소요됩니다.\")\n",
    "    print(f\"   로그 확인: az containerapp logs show --name agent-service --resource-group {RESOURCE_GROUP} --tail 50\")\n",
    "else:\n",
    "    print(f\"❌ Failed to start: {result.stderr}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cc46f0",
   "metadata": {},
   "source": [
    "## 10. 🚀 배포된 Agent 테스트 (Test Deployed Agent via HTTP)\n",
    "\n",
    "**중요한 차이점:**\n",
    "\n",
    "이전 섹션 6, 7에서는 **노트북에서 로컬로 Agent를 생성**하여 테스트했습니다.\n",
    "- ❌ 로컬 테스트 → Application Analytics에 **데이터가 나타나지 않습니다**\n",
    "\n",
    "이 섹션에서는 **배포된 Container의 HTTP API**를 호출합니다.\n",
    "- ✅ Container 테스트 → Application Analytics에 **데이터가 나타납니다**\n",
    "- ✅ Container 테스트 → **Tracing**도 활성화됩니다 (상세 실행 로그)\n",
    "\n",
    "**왜 차이가 날까요?**\n",
    "- Application Analytics는 **Azure AI Foundry Project에서 실행된 Agent**만 추적합니다\n",
    "- 노트북은 로컬 환경이므로 별도로 추적됩니다\n",
    "- Container 내부의 Agent는 Project에 연결되어 있어 자동으로 추적됩니다\n",
    "\n",
    "**테스트 방법:**\n",
    "1. 배포된 Agent Service의 `/chat` 엔드포인트 호출\n",
    "2. 다양한 질문으로 Agent 테스트\n",
    "3. 5-10분 후 Application Analytics 확인\n",
    "4. **Tracing 탭**에서 상세 실행 흐름 확인 (LLM 요청, Tool 호출 등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9a9f49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 배포된 Agent Service 테스트 ===\n",
      "\n",
      "🌐 Agent Endpoint: https://agent-service.gentletree-a093330c.eastus.azurecontainerapps.io\n",
      "\n",
      "1️⃣ Health Check:\n",
      "   ✅ Health: {'status': 'healthy', 'service': 'Agent API Server'}\n",
      "\n",
      "2️⃣ Agent Status:\n",
      "   ✅ Status: running\n",
      "   📋 Agents:\n",
      "      ✅ main_agent: True\n",
      "      ✅ tool_agent: True\n",
      "      ✅ research_agent: True\n",
      "\n",
      "======================================================================\n",
      "\n",
      "💡 Agent Service가 정상 작동 중입니다!\n",
      "   다음 셀에서 실제 질문을 테스트하세요.\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "print(\"=== 배포된 Agent Service 테스트 ===\\n\")\n",
    "\n",
    "# Agent 엔드포인트 확인\n",
    "if not AGENT_ENDPOINT:\n",
    "    print(\"❌ AGENT_ENDPOINT가 설정되지 않았습니다!\")\n",
    "    print(\"   섹션 5.2를 먼저 실행하세요.\\n\")\n",
    "else:\n",
    "    print(f\"🌐 Agent Endpoint: {AGENT_ENDPOINT}\\n\")\n",
    "    \n",
    "    # 1. Health check\n",
    "    print(\"1️⃣ Health Check:\")\n",
    "    try:\n",
    "        response = requests.get(f\"{AGENT_ENDPOINT}/health\", timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            print(f\"   ✅ Health: {response.json()}\\n\")\n",
    "        else:\n",
    "            print(f\"   ❌ Health check failed: {response.status_code}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Error: {e}\\n\")\n",
    "    \n",
    "    # 2. Root endpoint 확인 (Agent 상태)\n",
    "    print(\"2️⃣ Agent Status:\")\n",
    "    try:\n",
    "        response = requests.get(f\"{AGENT_ENDPOINT}/\", timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            status = response.json()\n",
    "            print(f\"   ✅ Status: {status.get('status')}\")\n",
    "            print(f\"   📋 Agents:\")\n",
    "            for agent_name, available in status.get('agents', {}).items():\n",
    "                icon = \"✅\" if available else \"❌\"\n",
    "                print(f\"      {icon} {agent_name}: {available}\")\n",
    "            print()\n",
    "        else:\n",
    "            print(f\"   ❌ Status check failed: {response.status_code}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Error: {e}\\n\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"\\n💡 Agent Service가 정상 작동 중입니다!\")\n",
    "    print(\"   다음 셀에서 실제 질문을 테스트하세요.\\n\")\n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d087e2a",
   "metadata": {},
   "source": [
    "## 11. Main Agent 테스트 (다양한 질문)\n",
    "\n",
    "배포된 Main Agent에 다양한 질문을 보내서 Application Analytics 데이터를 생성합니다.\n",
    "\n",
    "### 📚 Research Agent의 Citation 기능\n",
    "\n",
    "Research Agent가 Azure AI Search를 사용하여 답변할 때, **자동으로 출처(citation)**를 표시합니다:\n",
    "\n",
    "**Citation 형식:**\n",
    "- `【3:0†source】` = 3번 메시지의 0번째 annotation\n",
    "- `【3:1†source】` = 3번 메시지의 1번째 annotation\n",
    "- `【4:0†source】` = 4번 메시지의 0번째 annotation\n",
    "\n",
    "**예시 응답:**\n",
    "```\n",
    "제주도 우도는 아름다운 자연 경관을 자랑하는 섬입니다【3:0†source】.\n",
    "성산일출봉은 유네스코 세계자연유산으로 등재되어 있습니다【3:1†source】.\n",
    "```\n",
    "\n",
    "**작동 원리:**\n",
    "1. `AzureAISearchTool`이 지식 베이스 검색\n",
    "2. 검색된 문서가 Agent context에 자동 주입\n",
    "3. LLM이 답변 생성 시 문서 참조\n",
    "4. Azure AI Foundry SDK가 자동으로 citation 추가\n",
    "5. Tracing UI에서 각 citation 클릭 시 원본 문서 확인 가능\n",
    "\n",
    "> 💡 **참고:** Citation은 Azure AI Foundry Agent Service의 내장 기능으로, 코드에서 별도로 구현하지 않아도 자동 생성됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63760639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 배포된 Main Agent 테스트 ===\n",
      "\n",
      "======================================================================\n",
      "[Test 1/3]\n",
      "질문: 안녕하세요.\n",
      "설명: 일반 대화\n",
      "======================================================================\n",
      "\n",
      "✅ 응답 성공 (HTTP 200) - 3923.7 ms\n",
      "\n",
      "📝 Agent 응답 (전체 표시):\n",
      "안녕하세요! 무엇을 도와드릴까요? 여행지 추천, 날씨 정보, 혹은 다른 궁금한 점이 있으시면 말씀해주세요! 😊\n",
      "\n",
      "======================================================================\n",
      "[Test 2/3]\n",
      "질문: 서울의 현재 날씨를 알려주세요. 온도와 체감온도, 날씨 상태, 습도, 바람 정보를 모두 포함해주세요.\n",
      "설명: 서울 상세 날씨 정보 (Tool Agent 사용)\n",
      "======================================================================\n",
      "\n",
      "✅ 응답 성공 (HTTP 200) - 8292.4 ms\n",
      "\n",
      "📝 Agent 응답 (전체 표시):\n",
      "현재 서울의 날씨는 다음과 같습니다:\n",
      "\n",
      "- **온도:** 18°C  \n",
      "- **체감 온도:** 17°C  \n",
      "- **날씨 상태:** 맑음  \n",
      "- **습도:** 45%  \n",
      "- **바람:** 북서쪽으로 시속 12km  \n",
      "\n",
      "추가적으로 궁금한 사항이 있으면 알려주세요!\n",
      "\n",
      "======================================================================\n",
      "[Test 3/3]\n",
      "질문: 제주도 여행 추천 명소를 알려주세요\n",
      "설명: 여행지 추천 (Research Agent 사용)\n",
      "======================================================================\n",
      "\n",
      "✅ 응답 성공 (HTTP 200) - 13150.0 ms\n",
      "\n",
      "📝 Agent 응답 (전체 표시):\n",
      "제주도는 아름다운 자연경관, 독특한 문화, 그리고 다양한 활동이 가능한 최고의 여행지입니다. 다음은 추천 명소들입니다:\n",
      "\n",
      "---\n",
      "\n",
      "### 1. **성산일출봉**\n",
      "- **특징**: 유네스코 세계자연유산으로 지정된 화산 분화구로 유명하며, 정상에서 일출을 감상할 수 있습니다.\n",
      "- **추천 활동**: 분화구 산책, 360도 파노라마 전망 감상, 제주 해녀들의 물질 공연 관람.\n",
      "- **주변 명소**: 섭지코지, 광치기해변.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. **함덕 해수욕장**\n",
      "- **특징**: 에메랄드빛 바다와 얕은 수심으로 가족 단위의 여행객에게 이상적인 장소입니다.\n",
      "- **추천 활동**: 해변 산책, 서우봉 등반, 감성 카페 탐방.\n",
      "- **주변 명소**: 김녕미로공원, 월정리 해변. 지역 특산음식, 성게미역국 및 전복죽도 맛보세요.\n",
      "\n",
      "---\n",
      "\n",
      "### 3. **우도**\n",
      "- **특징**: 소가 누워있는 모습처럼 보이는 섬으로, 국내 유일의 홍조단괴 해변인 서빈백사 해변이 유명합니다.\n",
      "- **추천 활동**: 자전거와 전기차로 섬 둘러보기, 우도봉 전망대 방문, 땅콩 아이스크림과 막걸리 맛보기.\n",
      "- **교통**: 성산포항에서 배편으로 이동 가능하며 약 15분 소요됩니다.\n",
      "\n",
      "---\n",
      "\n",
      "이 외에도 제주에는 다양한 명소가 많으니 여행 계획 시 참고하시어 제주도의 매력을 마음껏 즐겨보세요!【3:0†source】【3:1†source】【3:2†source】\n",
      "\n",
      "======================================================================\n",
      "\n",
      "📊 테스트 결과:\n",
      "   ✅ 성공: 3/3\n",
      "   ❌ 실패: 0/3\n",
      "   ⏱️  평균 지연 (client 측정): 8455.4 ms (p95≈8292.4 ms)\n",
      "   ℹ️  Portal의 Average inference call duration 과는 다를 수 있습니다 (서버 측 추적).\n",
      "\n",
      "🎉 3개의 Agent 호출이 성공했습니다!\n",
      "\n",
      "💡 다음 단계:\n",
      "   1. 5-10분 정도 기다리세요 (데이터 처리 시간)\n",
      "   2. Azure AI Foundry 포털 접속: https://ai.azure.com\n",
      "   3. 프로젝트 → '평가' → 'Application Analytics'\n",
      "   4. 시간 범위를 '지난 24시간'으로 설정\n",
      "   5. 메트릭 확인:\n",
      "      • Total inference calls: 3+ 건\n",
      "      • Average inference call duration: Portal 값 (클라이언트 측 평균 8455.4 ms 참고)\n",
      "      • Error rate: 0/3\n",
      "\n",
      "   📋 참고: 더 많은 요청을 보낼수록 데이터가 더 빨리 나타납니다.\n",
      "           이 셀을 여러 번 실행해도 됩니다!\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# 배포된 Main Agent에 다양한 질문 보내기\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import statistics\n",
    "\n",
    "print(\"=== 배포된 Main Agent 테스트 ===\\n\")\n",
    "\n",
    "# 테스트 케이스 (3개)\n",
    "test_cases = [\n",
    "    {\n",
    "        \"message\": \"안녕하세요.\",\n",
    "        \"description\": \"일반 대화\"\n",
    "    },\n",
    "    {\n",
    "        \"message\": \"서울의 현재 날씨를 알려주세요. 온도와 체감온도, 날씨 상태, 습도, 바람 정보를 모두 포함해주세요.\",\n",
    "        \"description\": \"서울 상세 날씨 정보 (Tool Agent 사용)\"\n",
    "    },\n",
    "    {\n",
    "        \"message\": \"제주도 여행 추천 명소를 알려주세요\",\n",
    "        \"description\": \"여행지 추천 (Research Agent 사용)\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 출력 옵션\n",
    "TRUNCATE = False           # True 로 하면 300자 미리보기\n",
    "PREVIEW_CHARS = 300\n",
    "\n",
    "success_count = 0\n",
    "fail_count = 0\n",
    "latencies = []\n",
    "\n",
    "for i, test in enumerate(test_cases, 1):\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"[Test {i}/{len(test_cases)}]\")\n",
    "    print(f\"질문: {test['message']}\")\n",
    "    print(f\"설명: {test['description']}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    try:\n",
    "        start_req = time.perf_counter()\n",
    "        response = requests.post(\n",
    "            f\"{AGENT_ENDPOINT}/chat\",\n",
    "            json={\"message\": test['message']},\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "            timeout=90\n",
    "        )\n",
    "        elapsed_req = (time.perf_counter() - start_req) * 1000  # ms\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            full_resp = result.get('response', 'No response') or ''\n",
    "            print(f\"\\n✅ 응답 성공 (HTTP {response.status_code}) - {elapsed_req:.1f} ms\")\n",
    "            latencies.append(elapsed_req)\n",
    "            print(f\"\\n📝 Agent 응답 (전체 표시):\" if not TRUNCATE else f\"\\n📝 Agent 응답 (앞 {PREVIEW_CHARS}자):\")\n",
    "            if TRUNCATE and len(full_resp) > PREVIEW_CHARS:\n",
    "                print(full_resp[:PREVIEW_CHARS] + '...')\n",
    "            else:\n",
    "                print(full_resp)\n",
    "            print()\n",
    "            success_count += 1\n",
    "        else:\n",
    "            print(f\"\\n❌ 요청 실패 (HTTP {response.status_code})\")\n",
    "            print(f\"오류: {response.text[:200]}\")\n",
    "            print()\n",
    "            fail_count += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ 오류 발생: {e}\")\n",
    "        print()\n",
    "        fail_count += 1\n",
    "    \n",
    "    if i < len(test_cases):\n",
    "        time.sleep(2)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n📊 테스트 결과:\")\n",
    "print(f\"   ✅ 성공: {success_count}/{len(test_cases)}\")\n",
    "print(f\"   ❌ 실패: {fail_count}/{len(test_cases)}\")\n",
    "\n",
    "if success_count > 0:\n",
    "    avg_latency = statistics.mean(latencies) if latencies else 0\n",
    "    p95_latency = (sorted(latencies)[int(len(latencies)*0.95)-1] if len(latencies) >= 2 else latencies[0]) if latencies else 0\n",
    "    print(f\"   ⏱️  평균 지연 (client 측정): {avg_latency:.1f} ms (p95≈{p95_latency:.1f} ms)\")\n",
    "    print(f\"   ℹ️  Portal의 Average inference call duration 과는 다를 수 있습니다 (서버 측 추적).\")\n",
    "    print(f\"\\n🎉 {success_count}개의 Agent 호출이 성공했습니다!\")\n",
    "    print(f\"\\n💡 다음 단계:\")\n",
    "    print(f\"   1. 5-10분 정도 기다리세요 (데이터 처리 시간)\")\n",
    "    print(f\"   2. Azure AI Foundry 포털 접속: https://ai.azure.com\")\n",
    "    print(f\"   3. 프로젝트 → '평가' → 'Application Analytics'\")\n",
    "    print(f\"   4. 시간 범위를 '지난 24시간'으로 설정\")\n",
    "    print(f\"   5. 메트릭 확인:\")\n",
    "    print(f\"      • Total inference calls: {success_count}+ 건\")\n",
    "    print(f\"      • Average inference call duration: Portal 값 (클라이언트 측 평균 {avg_latency:.1f} ms 참고)\")\n",
    "    print(f\"      • Error rate: {fail_count}/{len(test_cases)}\")\n",
    "    print(f\"\\n   📋 참고: 더 많은 요청을 보낼수록 데이터가 더 빨리 나타납니다.\")\n",
    "    print(f\"           이 셀을 여러 번 실행해도 됩니다!\")\n",
    "else:\n",
    "    print(f\"\\n❌ 모든 요청이 실패했습니다.\")\n",
    "    print(f\"   Container 로그를 확인하세요:\")\n",
    "    print(f\"   az containerapp logs show --name agent-service --resource-group {RESOURCE_GROUP} --tail 50\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a6ce5b",
   "metadata": {},
   "source": [
    "## 12. 배포 완료 및 요약 (Deployment Summary)\n",
    "\n",
    "축하합니다! Azure AI Foundry Agent Service 배포를 성공적으로 완료했습니다.\n",
    "\n",
    "### 배포된 리소스 (Deployed Resources)\n",
    "\n",
    "| 리소스 타입 | 용도 | 상태 |\n",
    "|------------|------|------|\n",
    "| MCP Server (Container App) | Model Context Protocol 도구 서버 | ✅ 배포됨 |\n",
    "| Agent Service (Container App) | Multi-Agent 시스템 (Foundry) | ✅ 배포됨 |\n",
    "| Main Agent | Task 분석 및 라우팅 | ✅ 작동 중 |\n",
    "| Tool Agent | MCP 도구 연동 (날씨 등) | ✅ 작동 중 |\n",
    "| Research Agent | RAG 기반 지식 검색 | ✅ 작동 중 |\n",
    "| Azure AI Search Connection | RAG 데이터 소스 | ✅ 연결됨 |\n",
    "| Application Insights | Analytics 및 Tracing | ✅ 활성화 |\n",
    "\n",
    "### 📝 중요 사항\n",
    "\n",
    "**현재 완료된 작업:**\n",
    "- ✅ MCP Server Docker 이미지 빌드 및 배포 완료\n",
    "- ✅ Agent Service Docker 이미지 빌드 및 배포 완료\n",
    "- ✅ Managed Identity 권한 설정 완료 (Azure AI User)\n",
    "- ✅ Multi-Agent 시스템 테스트 완료\n",
    "- ✅ Application Analytics 및 Tracing 활성화\n",
    "\n",
    "**Agent 엔드포인트:**\n",
    "- 🌐 Agent Service: `{AGENT_ENDPOINT}/chat` (POST)\n",
    "- 🌐 MCP Server: `{MCP_ENDPOINT}/mcp` (POST)\n",
    "\n",
    "**Analytics 확인:**\n",
    "- 📊 5-10분 후 [Azure AI Foundry Portal](https://ai.azure.com)에서 확인\n",
    "- 프로젝트 → 평가 → Application Analytics\n",
    "- Tracing 탭에서 상세 실행 로그 확인 가능\n",
    "\n",
    "### 다음 단계 (Next Steps)\n",
    "\n",
    "이제 다음 노트북으로 진행하세요:\n",
    "\n",
    "1. **Notebook 4: Agent Framework Workflow 배포** (`04_deploy_agent_framework.ipynb`)\n",
    "   - Microsoft Agent Framework (LangGraph 기반) 배포\n",
    "   - Workflow Pattern으로 Multi-Agent 구성\n",
    "   - Router Executor를 통한 AI 기반 인텐트 분류\n",
    "   - Workflow Context 기반 메시지 스트리밍\n",
    "   - Foundry Agent vs Framework Agent 비교\n",
    "\n",
    "**선택 사항:**\n",
    "- 현재 배포된 Foundry Agent를 계속 사용하거나\n",
    "- Framework Agent를 추가로 배포하여 두 패턴 비교 가능\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a2a642",
   "metadata": {},
   "source": [
    "## 13. Agent Evaluation 설정 (Agent Evaluation Setup)\n",
    "\n",
    "Azure AI Foundry는 Agent의 품질, 효율성, 위험성을 측정하는 다양한 내장 evaluator를 제공합니다.\n",
    "\n",
    "### Evaluation 유형\n",
    "\n",
    "**Performance Evaluators (성능 평가):**\n",
    "- **Intent Resolution**: Agent가 사용자 의도를 올바르게 파악했는지 평가\n",
    "- **Tool Call Accuracy**: Agent가 올바른 도구를 정확하게 호출했는지 평가  \n",
    "- **Task Adherence**: Agent가 지시사항을 충실히 따랐는지 평가\n",
    "\n",
    "**Safety Evaluators (안전성 평가):**\n",
    "- **Content Safety**: 부적절한 콘텐츠(폭력, 혐오 등) 포함 여부 평가\n",
    "- **Indirect Attack**: 간접적인 악의적 공격 시도 감지\n",
    "- **Code Vulnerability**: 생성된 코드의 보안 취약점 평가\n",
    "\n",
    "### Evaluation 데이터\n",
    "\n",
    "Evaluation은 테스트 쿼리 집합(`eval-queries.json`)을 Agent에 실행하여 진행됩니다:\n",
    "\n",
    "**필수 필드:**\n",
    "- `query`: Agent에 보낼 테스트 질문\n",
    "- `ground-truth` (선택): 예상 답변 (일부 evaluator에서 사용)\n",
    "\n",
    "**Evaluation 프로세스:**\n",
    "1. 각 query를 Agent에 전송\n",
    "2. Agent 응답 수집 및 실행 메트릭 측정\n",
    "3. Evaluator들이 응답 품질 평가\n",
    "4. 결과를 JSON 파일로 저장 및 AI Foundry에 업로드\n",
    "\n",
    "### 필요한 환경 변수\n",
    "\n",
    "- `AZURE_EXISTING_AIPROJECT_ENDPOINT`: AI Project endpoint  \n",
    "- `AZURE_AI_AGENT_DEPLOYMENT_NAME`: Evaluator용 모델 배포명\n",
    "- `AZURE_EXISTING_AGENT_ID` 또는 `AZURE_AI_AGENT_NAME`: 평가할 Agent ID/이름\n",
    "\n",
    "> 💡 **참고**: 이미 `.env` 파일에 설정되어 있으므로 별도 설정이 필요 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da1dea38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Creating Evaluation Test Queries ===\n",
      "\n",
      "✅ Created evals/eval-queries.json\n",
      "\n",
      "📋 Test Queries (5 total):\n",
      "\n",
      "   1. 안녕하세요. 가족 여행지를 추천받고 싶어요....\n",
      "   2. 부산의 현재 날씨를 알려주세요. 온도와 체감온도를 포함해주세요....\n",
      "   3. 제주도에서 가족과 함께 즐길 수 있는 여행지는 어디인가요?...\n",
      "   4. 서핑할 수 있는 해변을 추천해주세요....\n",
      "   5. 가을에 가기 좋은 단풍 명소는 어디인가요?...\n",
      "\n",
      "💡 각 쿼리는 Agent의 다른 기능을 테스트합니다:\n",
      "   • 일반 대화 및 여행 의도 파악 (Main Agent)\n",
      "   • 날씨 조회 (Tool Agent - MCP)\n",
      "   • 여행지 지식 검색 (Research Agent - RAG)\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# evals 디렉토리 생성\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "evals_dir = Path(\"evals\")\n",
    "evals_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"=== Creating Evaluation Test Queries ===\\n\")\n",
    "\n",
    "# 테스트 쿼리 정의\n",
    "eval_queries = [\n",
    "    {\n",
    "        \"query\": \"안녕하세요. 가족 여행지를 추천받고 싶어요.\",\n",
    "        \"ground-truth\": \"Agent는 인사에 응답하고, 여행지 추천을 위해 Research Agent를 호출해야 합니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"부산의 현재 날씨를 알려주세요. 온도와 체감온도를 포함해주세요.\",\n",
    "        \"ground-truth\": \"부산의 현재 날씨 정보를 정확하게 제공해야 하며, 온도와 체감온도를 모두 포함해야 합니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"제주도에서 가족과 함께 즐길 수 있는 여행지는 어디인가요?\",\n",
    "        \"ground-truth\": \"제주도의 가족 친화적인 여행지를 검색하여 추천해야 합니다. 자연 명소, 체험 활동, 접근성 등을 고려한 정보를 제공합니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"서핑할 수 있는 해변을 추천해주세요.\",\n",
    "        \"ground-truth\": \"서핑이 가능한 한국의 해변 여행지를 검색하여 추천해야 합니다. 양양, 부산 등의 서핑 명소 정보를 제공합니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"가을에 가기 좋은 단풍 명소는 어디인가요?\",\n",
    "        \"ground-truth\": \"가을 계절에 방문하기 좋은 단풍 명소를 검색하여 추천해야 합니다. 내장산, 설악산 등의 자연 명소 정보를 제공합니다.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# JSON 파일로 저장\n",
    "eval_queries_path = evals_dir / \"eval-queries.json\"\n",
    "with open(eval_queries_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(eval_queries, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"✅ Created {eval_queries_path}\")\n",
    "print(f\"\\n📋 Test Queries ({len(eval_queries)} total):\\n\")\n",
    "\n",
    "for i, query in enumerate(eval_queries, 1):\n",
    "    print(f\"   {i}. {query['query'][:60]}...\")\n",
    "\n",
    "print(\"\\n💡 각 쿼리는 Agent의 다른 기능을 테스트합니다:\")\n",
    "print(\"   • 일반 대화 및 여행 의도 파악 (Main Agent)\")\n",
    "print(\"   • 날씨 조회 (Tool Agent - MCP)\")\n",
    "print(\"   • 여행지 지식 검색 (Research Agent - RAG)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63005287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Running Agent Evaluation ===\n",
      "\n",
      "📋 Configuration:\n",
      "   Project: https://aoai-f5gn2xuprfeyy.services.ai.azure.com/api/projects/proj-f5gn2xuprfeyy\n",
      "   Model: gpt-4o\n",
      "   Test Queries: evals/eval-queries.json\n",
      "\n",
      "\n",
      "🔌 Connecting to AI Project...\n",
      "✅ Connected\n",
      "\n",
      "🤖 Creating Evaluation Agent...\n",
      "✅ Agent created: Evaluation Agent (ID: asst_RAZ6p3qDj1nHJZwzs8944esV)\n",
      "\n",
      "======================================================================\n",
      "📝 Executing Test Queries\n",
      "\n",
      "   Total queries: 5\n",
      "\n",
      "   [1/5] 안녕하세요. 가족 여행지를 추천받고 싶어요....\n",
      "✅ Agent created: Evaluation Agent (ID: asst_RAZ6p3qDj1nHJZwzs8944esV)\n",
      "\n",
      "======================================================================\n",
      "📝 Executing Test Queries\n",
      "\n",
      "   Total queries: 5\n",
      "\n",
      "   [1/5] 안녕하세요. 가족 여행지를 추천받고 싶어요....\n",
      "      ✅ Completed in 18.7s\n",
      "         Tokens: 112 prompt + 1040 completion\n",
      "\n",
      "   [2/5] 부산의 현재 날씨를 알려주세요. 온도와 체감온도를 포함해주세요....\n",
      "      ✅ Completed in 18.7s\n",
      "         Tokens: 112 prompt + 1040 completion\n",
      "\n",
      "   [2/5] 부산의 현재 날씨를 알려주세요. 온도와 체감온도를 포함해주세요....\n",
      "      ✅ Completed in 6.8s\n",
      "         Tokens: 120 prompt + 309 completion\n",
      "\n",
      "   [3/5] 제주도에서 가족과 함께 즐길 수 있는 여행지는 어디인가요?...\n",
      "      ✅ Completed in 6.8s\n",
      "         Tokens: 120 prompt + 309 completion\n",
      "\n",
      "   [3/5] 제주도에서 가족과 함께 즐길 수 있는 여행지는 어디인가요?...\n",
      "      ✅ Completed in 18.3s\n",
      "         Tokens: 117 prompt + 1174 completion\n",
      "\n",
      "   [4/5] 서핑할 수 있는 해변을 추천해주세요....\n",
      "      ✅ Completed in 18.3s\n",
      "         Tokens: 117 prompt + 1174 completion\n",
      "\n",
      "   [4/5] 서핑할 수 있는 해변을 추천해주세요....\n",
      "      ✅ Completed in 15.9s\n",
      "         Tokens: 111 prompt + 901 completion\n",
      "\n",
      "   [5/5] 가을에 가기 좋은 단풍 명소는 어디인가요?...\n",
      "      ✅ Completed in 15.9s\n",
      "         Tokens: 111 prompt + 901 completion\n",
      "\n",
      "   [5/5] 가을에 가기 좋은 단풍 명소는 어디인가요?...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class ToolCallAccuracyEvaluator: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntentResolutionEvaluator: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntentResolutionEvaluator: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class TaskAdherenceEvaluator: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class TaskAdherenceEvaluator: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ✅ Completed in 18.1s\n",
      "         Tokens: 115 prompt + 1149 completion\n",
      "\n",
      "======================================================================\n",
      "\n",
      "✅ All queries executed successfully\n",
      "   Input saved to: evals/eval-input.jsonl\n",
      "\n",
      "======================================================================\n",
      "🔬 Running Evaluators\n",
      "\n",
      "   Evaluators:\n",
      "      • ToolCallAccuracyEvaluator\n",
      "      • IntentResolutionEvaluator\n",
      "      • TaskAdherenceEvaluator\n",
      "\n",
      "   ⚠️  참고: eastus 리전에서는 일부 RAI 평가자가 지원되지 않습니다.\n",
      "      (CodeVulnerability, ContentSafety, IndirectAttack는 제외)\n",
      "\n",
      "   ⏳ This may take 1-2 minutes...\n",
      "\n",
      "2025-10-20 16:37:06 +0900 6256078848 execution.bulk     INFO     Finished 5 / 5 lines.\n",
      "2025-10-20 16:37:06 +0900 6256078848 execution.bulk     INFO     Average execution time for completed lines: 0.0 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-10-20 16:37:06 +0900 6239252480 execution.bulk     INFO     Finished 5 / 5 lines.\n",
      "2025-10-20 16:37:06 +0900 6239252480 execution.bulk     INFO     Average execution time for completed lines: 0.0 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-10-20 16:37:06 +0900 6256078848 execution.bulk     INFO     Finished 5 / 5 lines.\n",
      "2025-10-20 16:37:06 +0900 6256078848 execution.bulk     INFO     Average execution time for completed lines: 0.0 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-10-20 16:37:06 +0900 6239252480 execution.bulk     INFO     Finished 5 / 5 lines.\n",
      "2025-10-20 16:37:06 +0900 6239252480 execution.bulk     INFO     Average execution time for completed lines: 0.0 seconds. Estimated time for incomplete lines: 0.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregated metrics for evaluator is not a dictionary will not be logged as metrics\n",
      "Aggregated metrics for evaluator is not a dictionary will not be logged as metrics\n",
      "Aggregated metrics for evaluator is not a dictionary will not be logged as metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"tool_call_accuracy_20251020_073706_413222\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-10-20 07:37:06.413222+00:00\"\n",
      "Duration: \"0:00:01.002365\"\n",
      "\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"operational_metrics_20251020_073706_414637\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-10-20 07:37:06.414637+00:00\"\n",
      "Duration: \"0:00:01.001754\"\n",
      "\n",
      "2025-10-20 16:37:11 +0900 6272905216 execution.bulk     INFO     Finished 1 / 5 lines.\n",
      "2025-10-20 16:37:11 +0900 6272905216 execution.bulk     INFO     Average execution time for completed lines: 5.17 seconds. Estimated time for incomplete lines: 20.68 seconds.\n",
      "2025-10-20 16:37:11 +0900 6272905216 execution.bulk     INFO     Finished 1 / 5 lines.\n",
      "2025-10-20 16:37:11 +0900 6272905216 execution.bulk     INFO     Average execution time for completed lines: 5.17 seconds. Estimated time for incomplete lines: 20.68 seconds.\n",
      "2025-10-20 16:37:11 +0900 6272905216 execution.bulk     INFO     Finished 2 / 5 lines.\n",
      "2025-10-20 16:37:11 +0900 6272905216 execution.bulk     INFO     Average execution time for completed lines: 2.6 seconds. Estimated time for incomplete lines: 7.8 seconds.\n",
      "2025-10-20 16:37:11 +0900 6272905216 execution.bulk     INFO     Finished 2 / 5 lines.\n",
      "2025-10-20 16:37:11 +0900 6272905216 execution.bulk     INFO     Average execution time for completed lines: 2.6 seconds. Estimated time for incomplete lines: 7.8 seconds.\n",
      "2025-10-20 16:37:11 +0900 6272905216 execution.bulk     INFO     Finished 3 / 5 lines.\n",
      "2025-10-20 16:37:11 +0900 6272905216 execution.bulk     INFO     Average execution time for completed lines: 1.79 seconds. Estimated time for incomplete lines: 3.58 seconds.\n",
      "2025-10-20 16:37:11 +0900 6272905216 execution.bulk     INFO     Finished 3 / 5 lines.\n",
      "2025-10-20 16:37:11 +0900 6272905216 execution.bulk     INFO     Average execution time for completed lines: 1.79 seconds. Estimated time for incomplete lines: 3.58 seconds.\n",
      "2025-10-20 16:37:11 +0900 6272905216 execution.bulk     INFO     Finished 4 / 5 lines.\n",
      "2025-10-20 16:37:11 +0900 6272905216 execution.bulk     INFO     Average execution time for completed lines: 1.39 seconds. Estimated time for incomplete lines: 1.39 seconds.\n",
      "2025-10-20 16:37:11 +0900 6272905216 execution.bulk     INFO     Finished 4 / 5 lines.\n",
      "2025-10-20 16:37:11 +0900 6272905216 execution.bulk     INFO     Average execution time for completed lines: 1.39 seconds. Estimated time for incomplete lines: 1.39 seconds.\n",
      "2025-10-20 16:37:11 +0900 6289731584 execution.bulk     INFO     Finished 1 / 5 lines.\n",
      "2025-10-20 16:37:11 +0900 6289731584 execution.bulk     INFO     Average execution time for completed lines: 5.57 seconds. Estimated time for incomplete lines: 22.28 seconds.\n",
      "2025-10-20 16:37:11 +0900 6289731584 execution.bulk     INFO     Finished 1 / 5 lines.\n",
      "2025-10-20 16:37:11 +0900 6289731584 execution.bulk     INFO     Average execution time for completed lines: 5.57 seconds. Estimated time for incomplete lines: 22.28 seconds.\n",
      "2025-10-20 16:37:12 +0900 6272905216 execution.bulk     INFO     Finished 5 / 5 lines.\n",
      "2025-10-20 16:37:12 +0900 6272905216 execution.bulk     INFO     Average execution time for completed lines: 1.24 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-10-20 16:37:12 +0900 6272905216 execution.bulk     INFO     Finished 5 / 5 lines.\n",
      "2025-10-20 16:37:12 +0900 6272905216 execution.bulk     INFO     Average execution time for completed lines: 1.24 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-10-20 16:37:12 +0900 6289731584 execution.bulk     INFO     Finished 2 / 5 lines.\n",
      "2025-10-20 16:37:12 +0900 6289731584 execution.bulk     INFO     Average execution time for completed lines: 3.16 seconds. Estimated time for incomplete lines: 9.48 seconds.\n",
      "2025-10-20 16:37:12 +0900 6289731584 execution.bulk     INFO     Finished 2 / 5 lines.\n",
      "2025-10-20 16:37:12 +0900 6289731584 execution.bulk     INFO     Average execution time for completed lines: 3.16 seconds. Estimated time for incomplete lines: 9.48 seconds.\n",
      "2025-10-20 16:37:12 +0900 6289731584 execution.bulk     INFO     Finished 3 / 5 lines.\n",
      "2025-10-20 16:37:12 +0900 6289731584 execution.bulk     INFO     Average execution time for completed lines: 2.14 seconds. Estimated time for incomplete lines: 4.28 seconds.\n",
      "2025-10-20 16:37:12 +0900 6289731584 execution.bulk     INFO     Finished 3 / 5 lines.\n",
      "2025-10-20 16:37:12 +0900 6289731584 execution.bulk     INFO     Average execution time for completed lines: 2.14 seconds. Estimated time for incomplete lines: 4.28 seconds.\n",
      "2025-10-20 16:37:12 +0900 6289731584 execution.bulk     INFO     Finished 4 / 5 lines.\n",
      "2025-10-20 16:37:12 +0900 6289731584 execution.bulk     INFO     Average execution time for completed lines: 1.61 seconds. Estimated time for incomplete lines: 1.61 seconds.\n",
      "2025-10-20 16:37:12 +0900 6289731584 execution.bulk     INFO     Finished 4 / 5 lines.\n",
      "2025-10-20 16:37:12 +0900 6289731584 execution.bulk     INFO     Average execution time for completed lines: 1.61 seconds. Estimated time for incomplete lines: 1.61 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregated metrics for evaluator is not a dictionary will not be logged as metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"intent_resolution_20251020_073706_417623\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-10-20 07:37:06.417623+00:00\"\n",
      "Duration: \"0:00:06.523665\"\n",
      "\n",
      "2025-10-20 16:37:13 +0900 6289731584 execution.bulk     INFO     Finished 5 / 5 lines.\n",
      "2025-10-20 16:37:13 +0900 6289731584 execution.bulk     INFO     Average execution time for completed lines: 1.37 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-10-20 16:37:13 +0900 6289731584 execution.bulk     INFO     Finished 5 / 5 lines.\n",
      "2025-10-20 16:37:13 +0900 6289731584 execution.bulk     INFO     Average execution time for completed lines: 1.37 seconds. Estimated time for incomplete lines: 0.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregated metrics for evaluator is not a dictionary will not be logged as metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"task_adherence_20251020_073706_418545\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-10-20 07:37:06.418545+00:00\"\n",
      "Duration: \"0:00:07.522714\"\n",
      "\n",
      "======= Combined Run Summary (Per Evaluator) =======\n",
      "\n",
      "{\n",
      "    \"operational_metrics\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:00:01.001754\",\n",
      "        \"completed_lines\": 5,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": null\n",
      "    },\n",
      "    \"tool_call_accuracy\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:00:01.002365\",\n",
      "        \"completed_lines\": 5,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": null\n",
      "    },\n",
      "    \"intent_resolution\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:00:06.523665\",\n",
      "        \"completed_lines\": 5,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": null\n",
      "    },\n",
      "    \"task_adherence\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:00:07.522714\",\n",
      "        \"completed_lines\": 5,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": null\n",
      "    }\n",
      "}\n",
      "\n",
      "====================================================\n",
      "\n",
      "Evaluation results saved to \"/Users/junwoojeong/GitHub/agentic-ai-labs/evals/eval-output.json\".\n",
      "\n",
      "✅ Evaluation completed!\n",
      "\n",
      "🧹 Cleaning up...\n",
      "✅ Evaluation Agent deleted: asst_RAZ6p3qDj1nHJZwzs8944esV\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Agent Evaluation 실행\n",
    "import time\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlparse\n",
    "from azure.ai.agents.models import RunStatus, MessageRole\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.evaluation import (\n",
    "    AIAgentConverter, evaluate, ToolCallAccuracyEvaluator, IntentResolutionEvaluator, \n",
    "    TaskAdherenceEvaluator\n",
    ")\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "print(\"=== Running Agent Evaluation ===\\n\")\n",
    "\n",
    "# 파일 경로 설정\n",
    "current_dir = Path(\".\")\n",
    "evals_dir = current_dir / \"evals\"\n",
    "eval_queries_path = evals_dir / \"eval-queries.json\"\n",
    "eval_input_path = evals_dir / \"eval-input.jsonl\"\n",
    "eval_output_path = evals_dir / \"eval-output.json\"\n",
    "\n",
    "# 환경 변수 로드 (이미 config에서 로드됨)\n",
    "project_endpoint = simple_project_conn\n",
    "parsed_endpoint = urlparse(project_endpoint)\n",
    "model_endpoint = f\"{parsed_endpoint.scheme}://{parsed_endpoint.netloc}\"\n",
    "deployment_name = config.get(\"model_deployment_name\", \"gpt-4o\")\n",
    "\n",
    "print(f\"📋 Configuration:\")\n",
    "print(f\"   Project: {project_endpoint}\")\n",
    "print(f\"   Model: {deployment_name}\")\n",
    "print(f\"   Test Queries: {eval_queries_path}\")\n",
    "print(f\"\\n\")\n",
    "\n",
    "# Initialize AIProjectClient\n",
    "print(\"🔌 Connecting to AI Project...\")\n",
    "credential = DefaultAzureCredential()\n",
    "ai_project = AIProjectClient(\n",
    "    credential=credential,\n",
    "    endpoint=project_endpoint,\n",
    "    api_version=\"2025-05-15-preview\"  # Evaluations require preview API\n",
    ")\n",
    "print(\"✅ Connected\\n\")\n",
    "\n",
    "# Evaluation용 Agent 생성\n",
    "print(\"🤖 Creating Evaluation Agent...\")\n",
    "eval_agent = ai_project.agents.create_agent(\n",
    "    model=deployment_name,\n",
    "    name=\"Evaluation Agent\",\n",
    "    instructions=\"\"\"You are a helpful travel and weather assistant.\n",
    "    \n",
    "You can help users with:\n",
    "1. Travel recommendations and destination information\n",
    "2. Weather information for any city\n",
    "3. General travel planning advice\n",
    "\n",
    "Be friendly, informative, and provide detailed responses.\"\"\"\n",
    ")\n",
    "print(f\"✅ Agent created: {eval_agent.name} (ID: {eval_agent.id})\\n\")\n",
    "\n",
    "# Setup evaluation config\n",
    "api_version = config.get(\"api_version\", \"2024-08-01-preview\")\n",
    "model_config = {\n",
    "    \"azure_deployment\": deployment_name,\n",
    "    \"azure_endpoint\": model_endpoint,\n",
    "    \"api_version\": api_version,\n",
    "}\n",
    "\n",
    "thread_data_converter = AIAgentConverter(ai_project)\n",
    "\n",
    "# 테스트 쿼리 실행 및 evaluation input 준비\n",
    "print(\"=\"*70)\n",
    "print(\"📝 Executing Test Queries\\n\")\n",
    "\n",
    "with open(eval_queries_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "print(f\"   Total queries: {len(test_data)}\\n\")\n",
    "\n",
    "with open(eval_input_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for idx, row in enumerate(test_data, 1):\n",
    "        query_text = row.get(\"query\")\n",
    "        print(f\"   [{idx}/{len(test_data)}] {query_text[:50]}...\")\n",
    "        \n",
    "        # 새 스레드 생성 (각 쿼리를 격리)\n",
    "        thread = ai_project.agents.threads.create()\n",
    "        \n",
    "        # 사용자 쿼리 생성\n",
    "        ai_project.agents.messages.create(\n",
    "            thread.id, role=MessageRole.USER, content=query_text\n",
    "        )\n",
    "        \n",
    "        # Agent 실행 및 성능 측정\n",
    "        start_time = time.time()\n",
    "        run = ai_project.agents.runs.create_and_process(\n",
    "            thread_id=thread.id, agent_id=eval_agent.id\n",
    "        )\n",
    "        end_time = time.time()\n",
    "        \n",
    "        if run.status != RunStatus.COMPLETED:\n",
    "            print(f\"      ⚠️  Run failed: {run.last_error or 'Unknown error'}\")\n",
    "            continue\n",
    "        \n",
    "        # 운영 메트릭 수집\n",
    "        operational_metrics = {\n",
    "            \"server-run-duration-in-seconds\": (\n",
    "                run.completed_at - run.created_at\n",
    "            ).total_seconds(),\n",
    "            \"client-run-duration-in-seconds\": end_time - start_time,\n",
    "            \"completion-tokens\": run.usage.completion_tokens,\n",
    "            \"prompt-tokens\": run.usage.prompt_tokens,\n",
    "            \"ground-truth\": row.get(\"ground-truth\", '')\n",
    "        }\n",
    "        \n",
    "        # Thread 데이터 + 운영 메트릭을 evaluation input에 추가\n",
    "        evaluation_data = thread_data_converter.prepare_evaluation_data(thread_ids=thread.id)\n",
    "        eval_item = evaluation_data[0]\n",
    "        eval_item[\"metrics\"] = operational_metrics\n",
    "        f.write(json.dumps(eval_item, ensure_ascii=False) + \"\\n\")\n",
    "        \n",
    "        print(f\"      ✅ Completed in {operational_metrics['client-run-duration-in-seconds']:.1f}s\")\n",
    "        print(f\"         Tokens: {operational_metrics['prompt-tokens']} prompt + {operational_metrics['completion-tokens']} completion\\n\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"\\n✅ All queries executed successfully\")\n",
    "print(f\"   Input saved to: {eval_input_path}\\n\")\n",
    "\n",
    "# Evaluation 실행\n",
    "print(\"=\"*70)\n",
    "print(\"🔬 Running Evaluators\\n\")\n",
    "\n",
    "print(\"   Evaluators:\")\n",
    "print(\"      • ToolCallAccuracyEvaluator\")\n",
    "print(\"      • IntentResolutionEvaluator\")\n",
    "print(\"      • TaskAdherenceEvaluator\")\n",
    "print(\"\\n   ⚠️  참고: eastus 리전에서는 일부 RAI 평가자가 지원되지 않습니다.\")\n",
    "print(\"      (CodeVulnerability, ContentSafety, IndirectAttack는 제외)\\n\")\n",
    "print(\"   ⏳ This may take 1-2 minutes...\\n\")\n",
    "\n",
    "# OperationalMetricsEvaluator 정의\n",
    "class OperationalMetricsEvaluator:\n",
    "    \"\"\"Propagate operational metrics to the final evaluation results\"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, *, metrics: dict, **kwargs):\n",
    "        return metrics\n",
    "\n",
    "# Evaluation 실행 (리전에서 지원되지 않는 평가자 제외)\n",
    "results = evaluate(\n",
    "    evaluation_name=\"foundry-agent-evaluation\",\n",
    "    data=eval_input_path,\n",
    "    evaluators={\n",
    "        \"operational_metrics\": OperationalMetricsEvaluator(),\n",
    "        \"tool_call_accuracy\": ToolCallAccuracyEvaluator(model_config=model_config),\n",
    "        \"intent_resolution\": IntentResolutionEvaluator(model_config=model_config),\n",
    "        \"task_adherence\": TaskAdherenceEvaluator(model_config=model_config),\n",
    "        # eastus 리전에서 지원되지 않는 평가자들은 제외\n",
    "        # \"code_vulnerability\": CodeVulnerabilityEvaluator(credential=credential, azure_ai_project=project_endpoint),\n",
    "        # \"content_safety\": ContentSafetyEvaluator(credential=credential, azure_ai_project=project_endpoint),\n",
    "        # \"indirect_attack\": IndirectAttackEvaluator(credential=credential, azure_ai_project=project_endpoint)\n",
    "    },\n",
    "    output_path=eval_output_path,\n",
    "    # azure_ai_project 파라미터를 제거하여 로컬에서만 평가 실행 (권한 문제 회피)\n",
    "    # azure_ai_project=project_endpoint,\n",
    ")\n",
    "\n",
    "print(\"✅ Evaluation completed!\\n\")\n",
    "\n",
    "# Evaluation Agent 삭제\n",
    "print(\"🧹 Cleaning up...\")\n",
    "ai_project.agents.delete_agent(eval_agent.id)\n",
    "print(f\"✅ Evaluation Agent deleted: {eval_agent.id}\\n\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1435c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation 결과 표시\n",
    "def print_eval_results(results, input_path, output_path):\n",
    "    \"\"\"Print the evaluation results in a formatted table\"\"\"\n",
    "    metrics = results.get(\"metrics\", {})\n",
    "    \n",
    "    if not metrics:\n",
    "        print(\"❌ No metrics found in results\")\n",
    "        return\n",
    "    \n",
    "    # Get the maximum length for formatting\n",
    "    key_len = max(len(key) for key in metrics.keys()) + 5\n",
    "    value_len = 20\n",
    "    full_len = key_len + value_len + 5\n",
    "    \n",
    "    # Format the header\n",
    "    print(\"\\n\" + \"=\" * full_len)\n",
    "    print(\"Evaluation Results\".center(full_len))\n",
    "    print(\"=\" * full_len)\n",
    "    \n",
    "    # Categorize metrics\n",
    "    operational = {}\n",
    "    performance = {}\n",
    "    safety = {}\n",
    "    \n",
    "    for key, value in metrics.items():\n",
    "        if any(x in key for x in ['duration', 'tokens', 'ground-truth']):\n",
    "            operational[key] = value\n",
    "        elif any(x in key for x in ['vulnerability', 'safety', 'attack']):\n",
    "            safety[key] = value\n",
    "        else:\n",
    "            performance[key] = value\n",
    "    \n",
    "    # Print operational metrics\n",
    "    if operational:\n",
    "        print(\"\\n📊 Operational Metrics\")\n",
    "        print(\"-\" * full_len)\n",
    "        for key, value in sorted(operational.items()):\n",
    "            if isinstance(value, float):\n",
    "                formatted_value = f\"{value:.2f}\"\n",
    "            else:\n",
    "                formatted_value = str(value)\n",
    "            print(f\"{key:<{key_len}} | {formatted_value}\")\n",
    "    \n",
    "    # Print performance metrics\n",
    "    if performance:\n",
    "        print(\"\\n⚡ Performance Metrics\")\n",
    "        print(\"-\" * full_len)\n",
    "        for key, value in sorted(performance.items()):\n",
    "            if isinstance(value, float):\n",
    "                formatted_value = f\"{value:.2f}\"\n",
    "            else:\n",
    "                formatted_value = str(value)\n",
    "            print(f\"{key:<{key_len}} | {formatted_value}\")\n",
    "    \n",
    "    # Print safety metrics\n",
    "    if safety:\n",
    "        print(\"\\n🛡️  Safety Metrics\")\n",
    "        print(\"-\" * full_len)\n",
    "        for key, value in sorted(safety.items()):\n",
    "            if isinstance(value, float):\n",
    "                formatted_value = f\"{value:.2f}\"\n",
    "            else:\n",
    "                formatted_value = str(value)\n",
    "            print(f\"{key:<{key_len}} | {formatted_value}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * full_len + \"\\n\")\n",
    "    \n",
    "    # Print additional information\n",
    "    print(f\"📁 Files:\")\n",
    "    print(f\"   Input:  {input_path}\")\n",
    "    print(f\"   Output: {output_path}\")\n",
    "    \n",
    "    if results.get(\"studio_url\"):\n",
    "        print(f\"\\n🌐 AI Foundry Portal:\")\n",
    "        print(f\"   {results['studio_url']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * full_len + \"\\n\")\n",
    "\n",
    "# 결과 표시\n",
    "print_eval_results(results, eval_input_path, eval_output_path)\n",
    "\n",
    "print(\"💡 다음 단계:\")\n",
    "print(\"   1. AI Foundry Portal에서 상세 결과 확인\")\n",
    "print(\"   2. 점수가 낮은 항목 분석\")\n",
    "print(\"   3. Agent 또는 프롬프트 개선\")\n",
    "print(\"   4. 재평가 및 비교\")\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9eaac4b",
   "metadata": {},
   "source": [
    "## 15. Evaluation 요약 (Evaluation Summary)\n",
    "\n",
    "### 완료된 작업\n",
    "\n",
    "✅ **Evaluation 환경 설정**\n",
    "- azure-ai-evaluation 패키지 설치\n",
    "- 테스트 쿼리 파일 생성 (eval-queries.json)\n",
    "\n",
    "✅ **Agent Evaluation 실행**\n",
    "- 배포된 Agent에 대해 테스트 쿼리 실행\n",
    "- 운영 메트릭 수집 (실행 시간, 토큰 사용량)\n",
    "- 6개의 evaluator로 품질 평가 수행\n",
    "- 결과를 JSON 파일로 저장\n",
    "- AI Foundry Portal에 결과 업로드\n",
    "\n",
    "✅ **결과 분석**\n",
    "- 운영 메트릭: 성능 및 효율성\n",
    "- 성능 메트릭: 도구 호출, 의도 파악, 지시 준수\n",
    "- 안전성 메트릭: 코드 취약점, 콘텐츠 안전성, 공격 감지\n",
    "\n",
    "### Evaluation 파일\n",
    "\n",
    "```\n",
    "evals/\n",
    "├── eval-queries.json      # 테스트 쿼리 (5개)\n",
    "├── eval-input.jsonl       # Agent 실행 결과 + 메트릭\n",
    "└── eval-output.json       # Evaluator 점수 및 상세 결과\n",
    "```\n",
    "\n",
    "### AI Foundry Portal에서 확인\n",
    "\n",
    "**Evaluations 탭:**\n",
    "1. AI Foundry Portal (https://ai.azure.com) 접속\n",
    "2. 프로젝트 선택\n",
    "3. \"Evaluations\" 또는 \"평가\" 탭 클릭\n",
    "4. \"foundry-agent-evaluation\" 결과 확인\n",
    "\n",
    "**확인 가능한 정보:**\n",
    "- 전체 점수 요약 (평균, 최소, 최대)\n",
    "- 각 쿼리별 상세 점수\n",
    "- Evaluator별 분석 결과\n",
    "- 시간 경과에 따른 개선 추적\n",
    "\n",
    "### 다음 단계\n",
    "\n",
    "**Evaluation을 활용한 개선:**\n",
    "\n",
    "1. **점수 분석**\n",
    "   - 낮은 점수를 받은 쿼리 확인\n",
    "   - 어떤 evaluator에서 문제가 발생했는지 파악\n",
    "\n",
    "2. **Agent 개선**\n",
    "   - 프롬프트 수정 (instructions)\n",
    "   - Tool 추가 또는 개선\n",
    "   - RAG 데이터 보강\n",
    "\n",
    "3. **재평가**\n",
    "   - 동일한 쿼리로 재평가\n",
    "   - 점수 비교 및 개선 확인\n",
    "\n",
    "4. **CI/CD 통합** (선택사항)\n",
    "   - GitHub Actions로 자동 평가\n",
    "   - PR마다 성능 회귀 테스트\n",
    "   - [AI Agent Evaluation Action](https://github.com/microsoft/ai-agent-evals) 사용\n",
    "\n",
    "### 참고 자료\n",
    "\n",
    "- [Azure AI Foundry Agent Evaluation](https://learn.microsoft.com/azure/ai-foundry/how-to/develop/agent-evaluate-sdk)\n",
    "- [Built-in Evaluators](https://learn.microsoft.com/azure/ai-foundry/how-to/develop/evaluate-sdk)\n",
    "- [Sample: get-started-with-ai-agents/evals](https://github.com/Azure-Samples/get-started-with-ai-agents/tree/main/evals)\n",
    "\n",
    "### 최종 요약\n",
    "\n",
    "축하합니다! Agent Evaluation을 성공적으로 완료했습니다.\n",
    "\n",
    "**배포된 시스템:**\n",
    "- ✅ Multi-Agent System (Main, Tool, Research)\n",
    "- ✅ MCP Server (날씨 도구)\n",
    "- ✅ Application Analytics (메트릭 추적)\n",
    "- ✅ **Agent Evaluation (품질 평가)** ← 이번 섹션에서 추가\n",
    "\n",
    "이제 다음 노트북으로 진행할 수 있습니다:\n",
    "- **Notebook 4**: Agent Framework Workflow (LangGraph 기반)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc97d932",
   "metadata": {},
   "source": [
    "## 17. Evaluation 결과 확인 (View Evaluation Results)\n",
    "\n",
    "Evaluation 결과를 포맷팅하여 표시합니다.\n",
    "\n",
    "### 결과 메트릭\n",
    "\n",
    "**Operational Metrics (운영 메트릭):**\n",
    "- `server-run-duration-in-seconds`: 서버 측 실행 시간\n",
    "- `client-run-duration-in-seconds`: 클라이언트 측 실행 시간  \n",
    "- `completion-tokens`: 생성된 토큰 수\n",
    "- `prompt-tokens`: 입력 토큰 수\n",
    "\n",
    "**Performance Metrics (성능 메트릭):**\n",
    "- `tool_call_accuracy.*`: 도구 호출 정확도 점수\n",
    "- `intent_resolution.*`: 의도 파악 점수\n",
    "- `task_adherence.*`: 지시사항 준수 점수\n",
    "\n",
    "**Safety Metrics (안전성 메트릭):**\n",
    "- `code_vulnerability.*`: 코드 취약점 점수\n",
    "- `content_safety.*`: 콘텐츠 안전성 점수  \n",
    "- `indirect_attack.*`: 간접 공격 감지 점수\n",
    "\n",
    "> 💡 **참고**: 점수가 높을수록 좋습니다. 대부분의 메트릭은 0-5 또는 1-5 범위입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ae0c73",
   "metadata": {},
   "source": [
    "## 16. Agent에서 직접 Evaluation 실행 (Run Agent Evaluation)\n",
    "\n",
    "배포된 Agent에 대해 evaluation을 실행합니다.\n",
    "\n",
    "### Evaluation 프로세스\n",
    "\n",
    "1. **Agent 준비**: 배포된 Agent ID/이름 확인\n",
    "2. **쿼리 실행**: 각 테스트 쿼리를 Agent에 전송하고 응답 수집\n",
    "3. **메트릭 수집**: 실행 시간, 토큰 사용량 등 운영 메트릭 기록\n",
    "4. **Evaluation 실행**: 내장 evaluator들로 응답 품질 평가\n",
    "5. **결과 저장**: JSON 파일로 저장 및 AI Foundry에 업로드\n",
    "\n",
    "### Evaluators\n",
    "\n",
    "이 evaluation에서 사용하는 evaluator:\n",
    "\n",
    "**Performance Evaluators:**\n",
    "- `ToolCallAccuracyEvaluator`: 도구 호출 정확도\n",
    "- `IntentResolutionEvaluator`: 의도 파악 정확도\n",
    "- `TaskAdherenceEvaluator`: 지시사항 준수도\n",
    "\n",
    "**Safety Evaluators:**\n",
    "- `CodeVulnerabilityEvaluator`: 코드 보안 취약점\n",
    "- `ContentSafetyEvaluator`: 콘텐츠 안전성\n",
    "- `IndirectAttackEvaluator`: 간접 공격 감지\n",
    "\n",
    "### 실행 시간\n",
    "\n",
    "- 각 쿼리 실행: ~5-10초\n",
    "- Evaluation: ~30-60초\n",
    "- 전체 소요 시간: ~2-3분"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6bc08e",
   "metadata": {},
   "source": [
    "## 14. Evaluation 테스트 쿼리 생성 (Create Evaluation Test Queries)\n",
    "\n",
    "테스트용 쿼리 파일을 생성합니다. 각 쿼리는 Agent의 다양한 기능을 테스트합니다.\n",
    "\n",
    "**쿼리 종류:**\n",
    "1. **일반 대화**: Main Agent의 기본 대화 기능\n",
    "2. **Tool 사용**: Tool Agent의 MCP 도구 호출 (날씨 조회)\n",
    "3. **RAG 검색**: Research Agent의 지식 베이스 검색\n",
    "\n",
    "**Ground Truth (정답 참고):**\n",
    "- 일부 evaluator는 ground-truth를 사용하여 답변 품질을 평가\n",
    "- 선택사항이지만, 더 정확한 평가를 위해 포함 권장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d558af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure AI Evaluation 패키지 설치\n",
    "print(\"=== Installing Azure AI Evaluation Package ===\\n\")\n",
    "\n",
    "result = subprocess.run(\n",
    "    [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"azure-ai-evaluation\"],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"✅ azure-ai-evaluation installed successfully\")\n",
    "else:\n",
    "    print(f\"⚠️  Installation warning: {result.stderr}\")\n",
    "    print(\"   Proceeding anyway...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
