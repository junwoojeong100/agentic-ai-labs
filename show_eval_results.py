#!/usr/bin/env python3
"""
Evaluation ê²°ê³¼ ìƒì„¸ ì¶œë ¥ ìŠ¤í¬ë¦½íŠ¸
"""
import json
from pathlib import Path

def main():
    eval_output_path = Path("evals/eval-output.json")
    
    print("=" * 80)
    print("ğŸ“Š AGENT EVALUATION RESULTS (ìƒì„¸)")
    print("=" * 80 + "\n")
    
    if not eval_output_path.exists():
        print("âŒ í‰ê°€ ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        print(f"   íŒŒì¼ ê²½ë¡œ: {eval_output_path.absolute()}")
        print("\n   ë¨¼ì € 06_evaluate_agents.ipynbì˜ ì…€ 5ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.\n")
        return
    
    try:
        with open(eval_output_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        metrics = data.get('metrics', {})
        rows = data.get('rows', [])
        
        # 1. ì „ì²´ í‰ê·  ì ìˆ˜
        print("â­ ì „ì²´ í‰ê·  ì„±ëŠ¥ ì ìˆ˜")
        print("-" * 80)
        scores = [
            ('Intent Resolution', 'intent_resolution.intent_resolution', 'ì˜ë„ íŒŒì•…'),
            ('Task Adherence', 'task_adherence.task_adherence', 'ì‘ì—… ì¶©ì‹¤ë„'),
        ]
        
        for name, key, desc in scores:
            if key in metrics:
                score = metrics[key]
                stars = 'â˜…' * int(score) + 'â˜†' * (5 - int(score))
                bar = 'â–ˆ' * int(score * 4) + 'â–‘' * (20 - int(score * 4))
                print(f"  {name:20} {score:.2f}/5.0  {stars}  [{bar}]")
                print(f"  {'':20} â†’ {desc}")
        
        # 2. ìš´ì˜ ë©”íŠ¸ë¦­
        print("\n\nâš¡ ìš´ì˜ ë©”íŠ¸ë¦­ (í‰ê· )")
        print("-" * 80)
        
        operational_keys = [
            ('operational_metrics.server-run-duration-in-seconds', 'ì„œë²„ ì‹¤í–‰ ì‹œê°„', 's'),
            ('operational_metrics.client-run-duration-in-seconds', 'í´ë¼ì´ì–¸íŠ¸ ì‹¤í–‰ ì‹œê°„', 's'),
            ('operational_metrics.prompt-tokens', 'í”„ë¡¬í”„íŠ¸ í† í°', 'tokens'),
            ('operational_metrics.completion-tokens', 'ì™„ì„± í† í°', 'tokens'),
        ]
        
        for key, desc, unit in operational_keys:
            if key in metrics:
                value = metrics[key]
                if unit == 'tokens':
                    print(f"  {desc:25} {int(value):>8,} {unit}")
                else:
                    print(f"  {desc:25} {value:>8.2f} {unit}")
        
        # 3. ê°œë³„ ì¿¼ë¦¬ ê²°ê³¼
        if rows:
            print("\n\nğŸ“‹ ì¿¼ë¦¬ë³„ ìƒì„¸ ê²°ê³¼")
            print("=" * 80)
            
            for idx, row in enumerate(rows, 1):
                # ì¿¼ë¦¬ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                query = ""
                query_input = row.get('inputs.query', [])
                if isinstance(query_input, list):
                    for item in query_input:
                        if isinstance(item, dict) and item.get('role') == 'user':
                            content = item.get('content', [])
                            if isinstance(content, list) and len(content) > 0:
                                query = content[0].get('text', '')
                            break
                
                print(f"\n[Query {idx}]")
                print(f"ì§ˆë¬¸: {query[:100]}{'...' if len(query) > 100 else ''}")
                
                # ì ìˆ˜
                intent = row.get('outputs.intent_resolution.intent_resolution', 'N/A')
                task = row.get('outputs.task_adherence.task_adherence', 'N/A')
                tool = row.get('outputs.tool_call_accuracy.tool_call_accuracy', 'N/A')
                
                print(f"  Intent Resolution:  {intent if isinstance(intent, str) else f'{intent:.1f}/5.0'}")
                print(f"  Task Adherence:     {task if isinstance(task, str) else f'{task:.1f}/5.0'}")
                print(f"  Tool Call Accuracy: {tool}")
                
                # ìš´ì˜ ë©”íŠ¸ë¦­
                duration = row.get('outputs.operational_metrics.client-run-duration-in-seconds', 0)
                prompt_tokens = row.get('outputs.operational_metrics.prompt-tokens', 0)
                completion_tokens = row.get('outputs.operational_metrics.completion-tokens', 0)
                
                print(f"  ì‹¤í–‰ ì‹œê°„: {duration:.2f}s  |  í† í°: {prompt_tokens} + {completion_tokens} = {prompt_tokens + completion_tokens}")
                
                # í‰ê°€ ì´ìœ  (ìˆëŠ” ê²½ìš°)
                intent_reason = row.get('outputs.intent_resolution.intent_resolution_reason', '')
                if intent_reason and len(intent_reason) < 150:
                    print(f"  ğŸ’¬ í‰ê°€: {intent_reason}")
                
                print("-" * 80)
            
            # 4. í†µê³„ ìš”ì•½
            print("\n\nğŸ“ˆ í†µê³„ ìš”ì•½")
            print("=" * 80)
            
            intent_scores = []
            task_scores = []
            durations = []
            total_tokens = []
            
            for row in rows:
                intent = row.get('outputs.intent_resolution.intent_resolution')
                task = row.get('outputs.task_adherence.task_adherence')
                duration = row.get('outputs.operational_metrics.client-run-duration-in-seconds', 0)
                prompt = row.get('outputs.operational_metrics.prompt-tokens', 0)
                completion = row.get('outputs.operational_metrics.completion-tokens', 0)
                
                if isinstance(intent, (int, float)):
                    intent_scores.append(intent)
                if isinstance(task, (int, float)):
                    task_scores.append(task)
                if duration:
                    durations.append(duration)
                total_tokens.append(prompt + completion)
            
            if intent_scores:
                print(f"Intent Resolution í‰ê· :  {sum(intent_scores)/len(intent_scores):.2f}/5.0")
                print(f"  ìµœê³ : {max(intent_scores):.1f}  |  ìµœì €: {min(intent_scores):.1f}")
            
            if task_scores:
                print(f"\nTask Adherence í‰ê· :     {sum(task_scores)/len(task_scores):.2f}/5.0")
                print(f"  ìµœê³ : {max(task_scores):.1f}  |  ìµœì €: {min(task_scores):.1f}")
            
            if durations:
                print(f"\nì‹¤í–‰ ì‹œê°„ í‰ê· :           {sum(durations)/len(durations):.2f}s")
                print(f"  ìµœê³ : {max(durations):.2f}s  |  ìµœì €: {min(durations):.2f}s")
            
            if total_tokens:
                print(f"\ní† í° ì‚¬ìš© í‰ê· :           {sum(total_tokens)/len(total_tokens):.0f} tokens")
                print(f"  ìµœëŒ€: {max(total_tokens)}  |  ìµœì†Œ: {min(total_tokens)}")
        
        print("\n\n" + "=" * 80)
        print(f"âœ… ì´ {len(rows)}ê°œ ì¿¼ë¦¬ í‰ê°€ ì™„ë£Œ")
        print(f"ï¿½ ìƒì„¸ JSON íŒŒì¼: {eval_output_path.absolute()}")
        print("=" * 80 + "\n")
        
    except json.JSONDecodeError as e:
        print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
